{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Python>=3.10 is required, but Python==3.9.20 is currently installed \n",
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\54583374\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import cv2  \n",
    "import math \n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos preentrenados, visualizando con las utilidades de ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 174.2ms\n",
      "video 1/1 (frame 2/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 221.3ms\n",
      "video 1/1 (frame 3/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 148.9ms\n",
      "video 1/1 (frame 4/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.2ms\n",
      "video 1/1 (frame 5/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 143.8ms\n",
      "video 1/1 (frame 6/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 147.9ms\n",
      "video 1/1 (frame 7/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 165.7ms\n",
      "video 1/1 (frame 8/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 140.1ms\n",
      "video 1/1 (frame 9/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 136.5ms\n",
      "video 1/1 (frame 10/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 139.0ms\n",
      "video 1/1 (frame 11/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 137.7ms\n",
      "video 1/1 (frame 12/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 135.3ms\n",
      "video 1/1 (frame 13/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 131.6ms\n",
      "video 1/1 (frame 14/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.8ms\n",
      "video 1/1 (frame 15/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 178.1ms\n",
      "video 1/1 (frame 16/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 191.1ms\n",
      "video 1/1 (frame 17/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 125.0ms\n",
      "video 1/1 (frame 18/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 136.4ms\n",
      "video 1/1 (frame 19/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 131.7ms\n",
      "video 1/1 (frame 20/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 134.3ms\n",
      "video 1/1 (frame 21/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.9ms\n",
      "video 1/1 (frame 22/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.9ms\n",
      "video 1/1 (frame 23/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 136.2ms\n",
      "video 1/1 (frame 24/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 150.2ms\n",
      "video 1/1 (frame 25/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 127.7ms\n",
      "video 1/1 (frame 26/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 127.5ms\n",
      "video 1/1 (frame 27/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 128.1ms\n",
      "video 1/1 (frame 28/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 140.3ms\n",
      "video 1/1 (frame 29/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 129.5ms\n",
      "video 1/1 (frame 30/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 153.7ms\n",
      "video 1/1 (frame 31/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 130.3ms\n",
      "video 1/1 (frame 32/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.7ms\n",
      "video 1/1 (frame 33/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 128.5ms\n",
      "video 1/1 (frame 34/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 156.2ms\n",
      "video 1/1 (frame 35/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 139.9ms\n",
      "video 1/1 (frame 36/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 147.0ms\n",
      "video 1/1 (frame 37/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 150.7ms\n",
      "video 1/1 (frame 38/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 140.1ms\n",
      "video 1/1 (frame 39/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 176.9ms\n",
      "video 1/1 (frame 40/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 151.1ms\n",
      "video 1/1 (frame 41/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 185.0ms\n",
      "video 1/1 (frame 42/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 170.2ms\n",
      "video 1/1 (frame 43/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 164.1ms\n",
      "video 1/1 (frame 44/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 165.7ms\n",
      "video 1/1 (frame 45/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 144.4ms\n",
      "video 1/1 (frame 46/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 182.5ms\n",
      "video 1/1 (frame 47/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 159.0ms\n",
      "video 1/1 (frame 48/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 144.9ms\n",
      "video 1/1 (frame 49/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 179.7ms\n",
      "video 1/1 (frame 50/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 181.2ms\n",
      "video 1/1 (frame 51/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 173.4ms\n",
      "video 1/1 (frame 52/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 146.4ms\n",
      "video 1/1 (frame 53/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 171.1ms\n",
      "video 1/1 (frame 54/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 166.3ms\n",
      "video 1/1 (frame 55/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 176.1ms\n",
      "video 1/1 (frame 56/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 168.4ms\n",
      "video 1/1 (frame 57/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 168.2ms\n",
      "video 1/1 (frame 58/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.9ms\n",
      "video 1/1 (frame 59/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 134.2ms\n",
      "video 1/1 (frame 60/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 129.4ms\n",
      "video 1/1 (frame 61/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 125.5ms\n",
      "video 1/1 (frame 62/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.9ms\n",
      "video 1/1 (frame 63/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 134.9ms\n",
      "video 1/1 (frame 64/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 148.4ms\n",
      "video 1/1 (frame 65/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 148.1ms\n",
      "video 1/1 (frame 66/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 139.4ms\n",
      "video 1/1 (frame 67/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 125.8ms\n",
      "video 1/1 (frame 68/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 140.6ms\n",
      "video 1/1 (frame 69/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 137.9ms\n",
      "video 1/1 (frame 70/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 123.9ms\n",
      "video 1/1 (frame 71/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 149.2ms\n",
      "video 1/1 (frame 72/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 148.4ms\n",
      "video 1/1 (frame 73/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 144.3ms\n",
      "video 1/1 (frame 74/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 135.1ms\n",
      "video 1/1 (frame 75/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 139.3ms\n",
      "video 1/1 (frame 76/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 141.0ms\n",
      "video 1/1 (frame 77/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 154.0ms\n",
      "video 1/1 (frame 78/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 149.7ms\n",
      "video 1/1 (frame 79/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 153.6ms\n",
      "video 1/1 (frame 80/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 135.9ms\n",
      "video 1/1 (frame 81/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 141.0ms\n",
      "video 1/1 (frame 82/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 131.2ms\n",
      "video 1/1 (frame 83/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 157.2ms\n",
      "video 1/1 (frame 84/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 144.7ms\n",
      "video 1/1 (frame 85/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 144.5ms\n",
      "video 1/1 (frame 86/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 116.0ms\n",
      "video 1/1 (frame 87/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 147.2ms\n",
      "video 1/1 (frame 88/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 141.3ms\n",
      "video 1/1 (frame 89/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 161.4ms\n",
      "video 1/1 (frame 90/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 186.1ms\n",
      "video 1/1 (frame 91/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 194.7ms\n",
      "video 1/1 (frame 92/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 182.4ms\n",
      "video 1/1 (frame 93/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 196.6ms\n",
      "video 1/1 (frame 94/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 175.3ms\n",
      "video 1/1 (frame 95/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 211.8ms\n",
      "video 1/1 (frame 96/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 192.7ms\n",
      "video 1/1 (frame 97/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 208.4ms\n",
      "video 1/1 (frame 98/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 193.7ms\n",
      "video 1/1 (frame 99/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 221.2ms\n",
      "video 1/1 (frame 100/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 234.6ms\n",
      "video 1/1 (frame 101/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 179.5ms\n",
      "video 1/1 (frame 102/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 181.1ms\n",
      "video 1/1 (frame 103/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 170.7ms\n",
      "video 1/1 (frame 104/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 182.0ms\n",
      "video 1/1 (frame 105/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 207.0ms\n",
      "video 1/1 (frame 106/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 213.5ms\n",
      "video 1/1 (frame 107/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 201.2ms\n",
      "video 1/1 (frame 108/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 165.8ms\n",
      "video 1/1 (frame 109/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 213.5ms\n",
      "video 1/1 (frame 110/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 216.9ms\n",
      "video 1/1 (frame 111/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 208.2ms\n",
      "video 1/1 (frame 112/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 217.5ms\n",
      "video 1/1 (frame 113/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 198.9ms\n",
      "video 1/1 (frame 114/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 185.7ms\n",
      "video 1/1 (frame 115/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 229.4ms\n",
      "video 1/1 (frame 116/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 144.4ms\n",
      "video 1/1 (frame 117/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 200.4ms\n",
      "video 1/1 (frame 118/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 170.0ms\n",
      "video 1/1 (frame 119/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 185.5ms\n",
      "video 1/1 (frame 120/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 194.5ms\n",
      "video 1/1 (frame 121/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 191.7ms\n",
      "video 1/1 (frame 122/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 148.4ms\n",
      "video 1/1 (frame 123/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 180.4ms\n",
      "video 1/1 (frame 124/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 172.8ms\n",
      "video 1/1 (frame 125/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 176.0ms\n",
      "video 1/1 (frame 126/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 146.6ms\n",
      "video 1/1 (frame 127/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 166.3ms\n",
      "video 1/1 (frame 128/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 129.9ms\n",
      "video 1/1 (frame 129/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.6ms\n",
      "video 1/1 (frame 130/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 169.8ms\n",
      "video 1/1 (frame 131/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 131.8ms\n",
      "video 1/1 (frame 132/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 139.9ms\n",
      "video 1/1 (frame 133/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 135.0ms\n",
      "video 1/1 (frame 134/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 142.2ms\n",
      "video 1/1 (frame 135/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 224.7ms\n",
      "video 1/1 (frame 136/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 134.7ms\n",
      "video 1/1 (frame 137/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 130.2ms\n",
      "video 1/1 (frame 138/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 148.8ms\n",
      "video 1/1 (frame 139/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 141.7ms\n",
      "video 1/1 (frame 140/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 136.9ms\n",
      "video 1/1 (frame 141/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.1ms\n",
      "video 1/1 (frame 142/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 148.8ms\n",
      "video 1/1 (frame 143/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 138.5ms\n",
      "video 1/1 (frame 144/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 150.2ms\n",
      "video 1/1 (frame 145/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 144.0ms\n",
      "video 1/1 (frame 146/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 134.5ms\n",
      "video 1/1 (frame 147/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 140.7ms\n",
      "video 1/1 (frame 148/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.8ms\n",
      "video 1/1 (frame 149/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 136.7ms\n",
      "video 1/1 (frame 150/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.9ms\n",
      "video 1/1 (frame 151/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 145.6ms\n",
      "video 1/1 (frame 152/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 127.7ms\n",
      "video 1/1 (frame 153/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 129.5ms\n",
      "video 1/1 (frame 154/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 137.2ms\n",
      "video 1/1 (frame 155/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 138.7ms\n",
      "video 1/1 (frame 156/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 152.1ms\n",
      "video 1/1 (frame 157/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 139.1ms\n",
      "video 1/1 (frame 158/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 145.3ms\n",
      "video 1/1 (frame 159/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 119.2ms\n",
      "video 1/1 (frame 160/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 165.6ms\n",
      "video 1/1 (frame 161/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 140.1ms\n",
      "video 1/1 (frame 162/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 136.8ms\n",
      "video 1/1 (frame 163/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 124.4ms\n",
      "video 1/1 (frame 164/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 130.5ms\n",
      "video 1/1 (frame 165/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 137.9ms\n",
      "video 1/1 (frame 166/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 164.9ms\n",
      "video 1/1 (frame 167/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 137.2ms\n",
      "video 1/1 (frame 168/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 142.6ms\n",
      "video 1/1 (frame 169/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 164.4ms\n",
      "video 1/1 (frame 170/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 124.3ms\n",
      "video 1/1 (frame 171/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 120.7ms\n",
      "video 1/1 (frame 172/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 140.7ms\n",
      "video 1/1 (frame 173/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 167.4ms\n",
      "video 1/1 (frame 174/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.5ms\n",
      "video 1/1 (frame 175/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 131.8ms\n",
      "video 1/1 (frame 176/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 135.1ms\n",
      "video 1/1 (frame 177/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.3ms\n",
      "video 1/1 (frame 178/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 129.3ms\n",
      "video 1/1 (frame 179/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 128.1ms\n",
      "video 1/1 (frame 180/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.0ms\n",
      "video 1/1 (frame 181/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.8ms\n",
      "video 1/1 (frame 182/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 136.9ms\n",
      "video 1/1 (frame 183/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 139.6ms\n",
      "video 1/1 (frame 184/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 130.7ms\n",
      "video 1/1 (frame 185/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 139.7ms\n",
      "video 1/1 (frame 186/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 136.3ms\n",
      "video 1/1 (frame 187/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 124.0ms\n",
      "video 1/1 (frame 188/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.7ms\n",
      "video 1/1 (frame 189/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 128.2ms\n",
      "video 1/1 (frame 190/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.0ms\n",
      "video 1/1 (frame 191/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 131.1ms\n",
      "video 1/1 (frame 192/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 134.1ms\n",
      "video 1/1 (frame 193/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 152.1ms\n",
      "video 1/1 (frame 194/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 148.0ms\n",
      "video 1/1 (frame 195/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.6ms\n",
      "video 1/1 (frame 196/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 127.5ms\n",
      "video 1/1 (frame 197/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 134.3ms\n",
      "video 1/1 (frame 198/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.1ms\n",
      "video 1/1 (frame 199/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 153.2ms\n",
      "video 1/1 (frame 200/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 123.4ms\n",
      "video 1/1 (frame 201/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 128.3ms\n",
      "video 1/1 (frame 202/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 145.0ms\n",
      "video 1/1 (frame 203/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 130.2ms\n",
      "video 1/1 (frame 204/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.8ms\n",
      "video 1/1 (frame 205/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 140.0ms\n",
      "video 1/1 (frame 206/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 121.7ms\n",
      "video 1/1 (frame 207/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 144.7ms\n",
      "video 1/1 (frame 208/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 140.9ms\n",
      "video 1/1 (frame 209/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 143.8ms\n",
      "video 1/1 (frame 210/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 141.7ms\n",
      "video 1/1 (frame 211/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 136.2ms\n",
      "video 1/1 (frame 212/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 139.2ms\n",
      "video 1/1 (frame 213/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 156.0ms\n",
      "video 1/1 (frame 214/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 166.0ms\n",
      "video 1/1 (frame 215/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 128.4ms\n",
      "video 1/1 (frame 216/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 128.0ms\n",
      "video 1/1 (frame 217/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 138.8ms\n",
      "video 1/1 (frame 218/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 131.9ms\n",
      "video 1/1 (frame 219/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 133.7ms\n",
      "video 1/1 (frame 220/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 127.7ms\n",
      "video 1/1 (frame 221/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 129.0ms\n",
      "video 1/1 (frame 222/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 132.1ms\n",
      "video 1/1 (frame 223/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 133.0ms\n",
      "video 1/1 (frame 224/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 140.1ms\n",
      "video 1/1 (frame 225/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 132.4ms\n",
      "video 1/1 (frame 226/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 146.9ms\n",
      "video 1/1 (frame 227/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 145.9ms\n",
      "video 1/1 (frame 228/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 128.7ms\n",
      "video 1/1 (frame 229/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 141.1ms\n",
      "video 1/1 (frame 230/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 139.1ms\n",
      "video 1/1 (frame 231/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 145.8ms\n",
      "video 1/1 (frame 232/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 181.1ms\n",
      "video 1/1 (frame 233/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 192.0ms\n",
      "video 1/1 (frame 234/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 180.0ms\n",
      "video 1/1 (frame 235/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 166.2ms\n",
      "video 1/1 (frame 236/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 131.6ms\n",
      "video 1/1 (frame 237/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 150.0ms\n",
      "video 1/1 (frame 238/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 128.8ms\n",
      "video 1/1 (frame 239/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 139.6ms\n",
      "video 1/1 (frame 240/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 164.2ms\n",
      "video 1/1 (frame 241/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 148.5ms\n",
      "video 1/1 (frame 242/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 148.1ms\n",
      "video 1/1 (frame 243/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 138.4ms\n",
      "video 1/1 (frame 244/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 142.1ms\n",
      "video 1/1 (frame 245/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 124.4ms\n",
      "video 1/1 (frame 246/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 129.3ms\n",
      "video 1/1 (frame 247/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 153.1ms\n",
      "video 1/1 (frame 248/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 148.3ms\n",
      "video 1/1 (frame 249/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 135.9ms\n",
      "video 1/1 (frame 250/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 140.4ms\n",
      "video 1/1 (frame 251/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 150.3ms\n",
      "video 1/1 (frame 252/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 141.7ms\n",
      "video 1/1 (frame 253/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 148.5ms\n",
      "video 1/1 (frame 254/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 155.2ms\n",
      "video 1/1 (frame 255/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 146.5ms\n",
      "video 1/1 (frame 256/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 137.7ms\n",
      "video 1/1 (frame 257/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 155.4ms\n",
      "video 1/1 (frame 258/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 131.6ms\n",
      "video 1/1 (frame 259/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 138.7ms\n",
      "video 1/1 (frame 260/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 121.8ms\n",
      "video 1/1 (frame 261/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 123.1ms\n",
      "video 1/1 (frame 262/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 124.5ms\n",
      "video 1/1 (frame 263/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 126.4ms\n",
      "video 1/1 (frame 264/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 148.4ms\n",
      "video 1/1 (frame 265/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 126.0ms\n",
      "video 1/1 (frame 266/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 147.0ms\n",
      "video 1/1 (frame 267/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 152.0ms\n",
      "video 1/1 (frame 268/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 128.3ms\n",
      "video 1/1 (frame 269/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 112.5ms\n",
      "video 1/1 (frame 270/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 132.5ms\n",
      "video 1/1 (frame 271/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 125.5ms\n",
      "video 1/1 (frame 272/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 157.0ms\n",
      "video 1/1 (frame 273/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 139.9ms\n",
      "video 1/1 (frame 274/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 192.8ms\n",
      "video 1/1 (frame 275/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 130.2ms\n",
      "video 1/1 (frame 276/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 125.1ms\n",
      "video 1/1 (frame 277/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 128.1ms\n",
      "video 1/1 (frame 278/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 117.6ms\n",
      "video 1/1 (frame 279/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 131.4ms\n",
      "video 1/1 (frame 280/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 126.7ms\n",
      "video 1/1 (frame 281/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 142.8ms\n",
      "video 1/1 (frame 282/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 144.5ms\n",
      "video 1/1 (frame 283/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 135.5ms\n",
      "video 1/1 (frame 284/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 129.0ms\n",
      "video 1/1 (frame 285/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 154.2ms\n",
      "video 1/1 (frame 286/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 140.3ms\n",
      "video 1/1 (frame 287/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 141.4ms\n",
      "video 1/1 (frame 288/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 130.0ms\n",
      "video 1/1 (frame 289/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 152.0ms\n",
      "video 1/1 (frame 290/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 147.5ms\n",
      "video 1/1 (frame 291/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 157.2ms\n",
      "video 1/1 (frame 292/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 164.8ms\n",
      "video 1/1 (frame 293/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 124.4ms\n",
      "video 1/1 (frame 294/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 156.0ms\n",
      "video 1/1 (frame 295/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 130.9ms\n",
      "video 1/1 (frame 296/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 135.2ms\n",
      "video 1/1 (frame 297/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 157.0ms\n",
      "video 1/1 (frame 298/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 150.3ms\n",
      "video 1/1 (frame 299/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 133.5ms\n",
      "video 1/1 (frame 300/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 133.2ms\n",
      "video 1/1 (frame 301/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 133.1ms\n",
      "video 1/1 (frame 302/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 153.8ms\n",
      "video 1/1 (frame 303/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 150.1ms\n",
      "video 1/1 (frame 304/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 146.9ms\n",
      "video 1/1 (frame 305/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 166.6ms\n",
      "video 1/1 (frame 306/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 158.0ms\n",
      "video 1/1 (frame 307/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 154.5ms\n",
      "video 1/1 (frame 308/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 133.0ms\n",
      "video 1/1 (frame 309/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 167.1ms\n",
      "video 1/1 (frame 310/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 150.7ms\n",
      "video 1/1 (frame 311/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 155.7ms\n",
      "video 1/1 (frame 312/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 134.7ms\n",
      "video 1/1 (frame 313/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 127.3ms\n",
      "video 1/1 (frame 314/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 126.8ms\n",
      "video 1/1 (frame 315/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 154.9ms\n",
      "video 1/1 (frame 316/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 143.5ms\n",
      "video 1/1 (frame 317/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 150.1ms\n",
      "video 1/1 (frame 318/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 183.1ms\n",
      "video 1/1 (frame 319/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 186.6ms\n",
      "video 1/1 (frame 320/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 188.4ms\n",
      "video 1/1 (frame 321/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 183.7ms\n",
      "video 1/1 (frame 322/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 149.7ms\n",
      "video 1/1 (frame 323/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.8ms\n",
      "video 1/1 (frame 324/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 164.0ms\n",
      "video 1/1 (frame 325/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 137.5ms\n",
      "video 1/1 (frame 326/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 168.0ms\n",
      "video 1/1 (frame 327/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.0ms\n",
      "video 1/1 (frame 328/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 150.6ms\n",
      "video 1/1 (frame 329/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 1295.1ms\n",
      "video 1/1 (frame 330/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 143.5ms\n",
      "video 1/1 (frame 331/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 158.8ms\n",
      "video 1/1 (frame 332/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 163.4ms\n",
      "video 1/1 (frame 333/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.8ms\n",
      "video 1/1 (frame 334/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 150.9ms\n",
      "video 1/1 (frame 335/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.0ms\n",
      "video 1/1 (frame 336/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 148.1ms\n",
      "video 1/1 (frame 337/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.3ms\n",
      "video 1/1 (frame 338/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 145.3ms\n",
      "video 1/1 (frame 339/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 158.2ms\n",
      "video 1/1 (frame 340/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 128.1ms\n",
      "video 1/1 (frame 341/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.3ms\n",
      "video 1/1 (frame 342/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.1ms\n",
      "video 1/1 (frame 343/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 134.9ms\n",
      "video 1/1 (frame 344/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 166.9ms\n",
      "video 1/1 (frame 345/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.3ms\n",
      "video 1/1 (frame 346/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.5ms\n",
      "video 1/1 (frame 347/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 127.9ms\n",
      "video 1/1 (frame 348/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.5ms\n",
      "video 1/1 (frame 349/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 136.3ms\n",
      "video 1/1 (frame 350/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 131.9ms\n",
      "video 1/1 (frame 351/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 149.5ms\n",
      "video 1/1 (frame 352/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 140.0ms\n",
      "video 1/1 (frame 353/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 150.1ms\n",
      "video 1/1 (frame 354/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 155.5ms\n",
      "video 1/1 (frame 355/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 160.7ms\n",
      "video 1/1 (frame 356/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 129.4ms\n",
      "video 1/1 (frame 357/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 138.4ms\n",
      "video 1/1 (frame 358/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 126.4ms\n",
      "video 1/1 (frame 359/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 155.3ms\n",
      "video 1/1 (frame 360/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.1ms\n",
      "video 1/1 (frame 361/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 166.9ms\n",
      "video 1/1 (frame 362/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 131.4ms\n",
      "video 1/1 (frame 363/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 122.3ms\n",
      "video 1/1 (frame 364/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 148.5ms\n",
      "video 1/1 (frame 365/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.0ms\n",
      "video 1/1 (frame 366/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 130.5ms\n",
      "video 1/1 (frame 367/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 155.4ms\n",
      "video 1/1 (frame 368/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 133.1ms\n",
      "video 1/1 (frame 369/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 161.4ms\n",
      "video 1/1 (frame 370/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 145.1ms\n",
      "video 1/1 (frame 371/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 140.3ms\n",
      "video 1/1 (frame 372/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 142.1ms\n",
      "video 1/1 (frame 373/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 142.8ms\n",
      "video 1/1 (frame 374/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 137.6ms\n",
      "video 1/1 (frame 375/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 137.2ms\n",
      "Speed: 2.3ms preprocess, 151.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "#model = YOLO('yolo11n.pt') #Contenedores\n",
    "#model = YOLO('yolo11n-seg.pt') #Máscaras\n",
    "model = YOLO('YOLO/yolo11n-pose.pt')  #Pose\n",
    "\n",
    "#Para un vídeo \n",
    "filename = \"Material P4/TGC23_PdH_C0056cut.mp4\"\n",
    "results = model(filename, show=True)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde cámara, detección con yolo11, modelo nano. Visualización propia con OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 8.03MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 283.6ms\n",
      "Speed: 0.0ms preprocess, 283.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 258.5ms\n",
      "Speed: 3.8ms preprocess, 258.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 167.7ms\n",
      "Speed: 1.3ms preprocess, 167.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 226.9ms\n",
      "Speed: 0.9ms preprocess, 226.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 191.9ms\n",
      "Speed: 5.7ms preprocess, 191.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 167.5ms\n",
      "Speed: 3.0ms preprocess, 167.5ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 182.4ms\n",
      "Speed: 2.2ms preprocess, 182.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 178.5ms\n",
      "Speed: 2.0ms preprocess, 178.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 174.5ms\n",
      "Speed: 0.7ms preprocess, 174.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 174.4ms\n",
      "Speed: 2.7ms preprocess, 174.4ms inference, 15.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 179.7ms\n",
      "Speed: 3.2ms preprocess, 179.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 146.0ms\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> cell phone\n",
      "Speed: 2.0ms preprocess, 146.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 185.7ms\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> tvmonitor\n",
      "Speed: 4.0ms preprocess, 185.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 181.3ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 4.0ms preprocess, 181.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 170.2ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 170.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 218.9ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 218.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 167.5ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 167.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 154.1ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 154.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 130.2ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 130.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 157.2ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.6ms preprocess, 157.2ms inference, 14.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 133.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 133.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 171.0ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 3.3ms preprocess, 171.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 133.9ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 133.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 147.1ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.1ms preprocess, 147.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 142.2ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 142.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 132.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 132.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 156.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 156.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 159.5ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 159.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 141.6ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 141.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 232.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 232.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 160.0ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.2ms preprocess, 160.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 157.6ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 4.0ms preprocess, 157.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 153.2ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.2ms preprocess, 153.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 163.1ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 163.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 152.5ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 152.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 166.2ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 166.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 164.7ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 164.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 211.9ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 211.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 171.9ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 171.3ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 171.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 177.8ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 177.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 160.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 160.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 167.4ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 167.4ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 163.3ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 163.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 156.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 156.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 162.5ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 162.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 162.7ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 162.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 159.6ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 159.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 163.1ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 163.1ms inference, 0.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 146.3ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 146.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 154.9ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 154.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 135.3ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Speed: 1.3ms preprocess, 135.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 128.6ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 128.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 144.4ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 144.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 147.4ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 147.4ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 161.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 161.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 127.5ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> chair\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 127.5ms inference, 15.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 chair, 166.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 166.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 207.0ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 3.1ms preprocess, 207.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 182.1ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 182.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 153.1ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 153.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 144.4ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 144.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 158.3ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 158.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 149.8ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 149.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 146.8ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> cell phone\n",
      "Speed: 6.7ms preprocess, 146.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 150.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 156.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 156.3ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 3.5ms preprocess, 128.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 141.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 161.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 4.1ms preprocess, 161.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 1.2ms preprocess, 158.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 161.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 161.7ms inference, 7.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 128.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 2.6ms preprocess, 128.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.1ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 146.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 161.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 161.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 2.8ms preprocess, 158.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.5ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 145.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 155.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 155.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 147.7ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 161.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 161.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.6ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 151.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 156.2ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 135.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 135.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 132.1ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 132.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.9ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 150.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.5ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Speed: 2.6ms preprocess, 141.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 0.9ms preprocess, 147.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 156.5ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Speed: 0.9ms preprocess, 156.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.7ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 145.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 148.8ms\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 148.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 153.8ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.7ms preprocess, 153.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 156.5ms\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Speed: 2.5ms preprocess, 156.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 154.0ms\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 154.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 158.6ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 158.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 148.7ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 148.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cell phone, 149.6ms\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> cell phone\n",
      "Speed: 1.3ms preprocess, 149.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cell phone, 147.3ms\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 147.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 165.2ms\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 2.9ms preprocess, 165.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 159.9ms\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 159.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 165.5ms\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 165.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 168.1ms\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> cell phone\n",
      "Speed: 3.3ms preprocess, 168.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 146.8ms\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 146.8ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 158.7ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 158.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 150.2ms\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> cell phone\n",
      "Speed: 2.1ms preprocess, 150.2ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 136.1ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> cell phone\n",
      "Speed: 2.1ms preprocess, 136.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 remote, 1 cell phone, 161.4ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> remote\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 161.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 remote, 128.0ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> remote\n",
      "Speed: 2.1ms preprocess, 128.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cell phone, 156.6ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 0.9ms preprocess, 156.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cell phone, 153.0ms\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 153.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 cell phones, 169.9ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.83\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 169.9ms inference, 12.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 cell phones, 135.6ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> cell phone\n",
      "Speed: 4.7ms preprocess, 135.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 cell phones, 166.6ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.85\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 2.9ms preprocess, 166.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cell phone, 163.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 163.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 158.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> cell phone\n",
      "Speed: 3.0ms preprocess, 158.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cell phone, 160.2ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 4.3ms preprocess, 160.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 cell phones, 153.3ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> cell phone\n",
      "Speed: 3.1ms preprocess, 153.3ms inference, 8.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 151.1ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 151.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 152.4ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 0.7ms preprocess, 152.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cell phone, 143.7ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 143.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cell phone, 135.4ms\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 135.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 162.3ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 162.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 148.7ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 148.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 157.8ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> cell phone\n",
      "Speed: 2.0ms preprocess, 157.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 149.1ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 149.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 145.3ms\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 145.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cell phone, 142.8ms\n",
      "Confianza ---> 0.78\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 142.8ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 163.2ms\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 163.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.4ms\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 143.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 156.2ms\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.5ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 158.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.2ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 151.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 158.6ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 158.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 chair, 212.3ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 212.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 163.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 163.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 150.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Speed: 2.9ms preprocess, 150.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 157.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 157.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 150.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 150.7ms inference, 11.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 162.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 162.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 149.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Speed: 0.2ms preprocess, 149.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 137.1ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 137.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 138.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Speed: 3.1ms preprocess, 138.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 142.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 142.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 143.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 143.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 157.3ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 157.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 145.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 145.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 128.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 128.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 160.0ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Speed: 10.5ms preprocess, 160.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 158.1ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 158.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 129.6ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 129.6ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 144.4ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 144.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 161.5ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 161.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 144.8ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 144.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 158.1ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 158.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 136.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 136.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 154.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 154.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 165.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 165.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 158.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> cell phone\n",
      "Speed: 1.9ms preprocess, 158.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 142.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 142.3ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 155.8ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 155.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 151.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 151.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 160.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 160.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 159.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 159.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 152.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 152.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 153.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.2ms preprocess, 153.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 152.5ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 152.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 150.6ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 150.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 164.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 164.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 146.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 146.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 135.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 135.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 152.8ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 152.8ms inference, 8.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 139.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 139.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 153.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Speed: 7.6ms preprocess, 153.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 159.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 159.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 160.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 160.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 154.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 2.9ms preprocess, 154.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 157.0ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 157.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 141.1ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 141.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 155.5ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 155.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 156.2ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 154.7ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 154.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 152.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 0.3ms preprocess, 152.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 149.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 149.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 154.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 154.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 159.0ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 159.0ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 136.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 136.4ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 154.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 3.1ms preprocess, 154.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 151.5ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 151.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 155.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 155.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 153.3ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 153.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 162.6ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 162.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cell phone, 133.2ms\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> cell phone\n",
      "Speed: 3.0ms preprocess, 133.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 158.8ms\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 158.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 chair, 1 laptop, 157.8ms\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Confianza ---> 0.26\n",
      "Clase --> laptop\n",
      "Speed: 1.9ms preprocess, 157.8ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 chair, 1 cell phone, 152.5ms\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> chair\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 152.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 cell phone, 129.1ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 129.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 cell phone, 156.2ms\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 132.4ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 132.4ms inference, 6.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 162.1ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 162.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 152.9ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 152.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 159.6ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 159.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 159.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 159.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 190.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 190.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 155.4ms\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 155.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 163.4ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 3.4ms preprocess, 163.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.1ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 158.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 148.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 139.2ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 139.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 chairs, 145.4ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> chair\n",
      "Confianza ---> 0.36\n",
      "Clase --> chair\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 0.9ms preprocess, 145.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 cell phone, 167.9ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.37\n",
      "Clase --> chair\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 167.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 chairs, 1 cell phone, 123.4ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.29\n",
      "Clase --> chair\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 123.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 cell phone, 157.7ms\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> chair\n",
      "Confianza ---> 0.37\n",
      "Clase --> cell phone\n",
      "Speed: 2.0ms preprocess, 157.7ms inference, 9.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 chairs, 156.4ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> chair\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Speed: 3.7ms preprocess, 156.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 148.3ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Speed: 1.0ms preprocess, 148.3ms inference, 12.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 162.0ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 162.0ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 159.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 2.4ms preprocess, 159.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.7ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Speed: 1.3ms preprocess, 151.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 153.3ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> chair\n",
      "Speed: 4.4ms preprocess, 153.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 157.3ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 3.7ms preprocess, 157.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 123.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> chair\n",
      "Confianza ---> 0.33\n",
      "Clase --> chair\n",
      "Speed: 1.0ms preprocess, 123.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 143.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> chair\n",
      "Confianza ---> 0.29\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 143.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 cell phone, 162.6ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 0.0ms preprocess, 162.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 157.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> cell phone\n",
      "Speed: 2.3ms preprocess, 157.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 128.9ms\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 128.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 156.2ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> chair\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 156.2ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 157.7ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 157.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 167.5ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> chair\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 3.1ms preprocess, 167.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 chair, 149.6ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> chair\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 149.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 165.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 165.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 161.9ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> chair\n",
      "Speed: 2.2ms preprocess, 161.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 150.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 150.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 151.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 151.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 134.6ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> chair\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 134.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 129.3ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> chair\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 129.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 162.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 162.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 137.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Speed: 2.1ms preprocess, 137.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 148.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Speed: 0.0ms preprocess, 148.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 128.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> chair\n",
      "Speed: 3.9ms preprocess, 128.7ms inference, 18.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 151.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> chair\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 2.8ms preprocess, 151.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 159.6ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> chair\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 159.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 154.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> chair\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 154.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 133.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> chair\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 133.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 140.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> chair\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 3.2ms preprocess, 140.8ms inference, 15.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 156.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.2ms preprocess, 156.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 157.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 157.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 135.5ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 135.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 139.1ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 3.1ms preprocess, 139.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 156.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 156.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 155.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> chair\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 155.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 129.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> chair\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 129.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 162.0ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> chair\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 162.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 chairs, 125.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> chair\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> chair\n",
      "Speed: 3.7ms preprocess, 125.0ms inference, 13.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 165.0ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 165.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 164.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 164.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 152.2ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 152.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 157.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 157.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 138.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 138.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 153.5ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 153.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 156.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 156.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 124.1ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Speed: 3.2ms preprocess, 124.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 155.1ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 2.7ms preprocess, 155.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 151.0ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 151.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 155.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> chair\n",
      "Speed: 3.8ms preprocess, 155.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 158.2ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> chair\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 3.1ms preprocess, 158.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 155.4ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> chair\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Speed: 3.2ms preprocess, 155.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 153.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> chair\n",
      "Speed: 2.5ms preprocess, 153.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 163.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 4.1ms preprocess, 163.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 152.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 152.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 150.7ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> chair\n",
      "Speed: 2.1ms preprocess, 150.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 138.7ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> chair\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 138.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 201.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> chair\n",
      "Speed: 2.4ms preprocess, 201.8ms inference, 14.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 137.6ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> chair\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 137.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 153.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> chair\n",
      "Speed: 1.9ms preprocess, 153.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 142.4ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> chair\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 142.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 142.1ms\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.6ms preprocess, 142.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 161.8ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 161.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 140.6ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 166.2ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 2.6ms preprocess, 166.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 152.6ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 152.6ms inference, 12.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 135.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 135.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 126.1ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 126.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 152.8ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 152.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 160.9ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 160.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 153.6ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 153.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 153.7ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 153.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 162.2ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 162.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 138.9ms\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 138.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 155.4ms\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 155.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 155.4ms\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 155.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 163.8ms\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 163.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 145.0ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 145.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 127.5ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 127.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 158.4ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 158.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 163.2ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 163.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 164.3ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 164.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 137.6ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> chair\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 137.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 162.7ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Speed: 0.0ms preprocess, 162.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 140.0ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 3.4ms preprocess, 140.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 137.4ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 137.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 132.2ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 162.4ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 162.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 145.7ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Speed: 3.6ms preprocess, 145.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 134.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 134.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 157.3ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Speed: 2.4ms preprocess, 157.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 150.7ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 3.8ms preprocess, 150.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 159.3ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Speed: 2.1ms preprocess, 159.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 140.6ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> chair\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 3.2ms preprocess, 140.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 141.2ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 141.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 161.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 161.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 164.4ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 164.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 146.0ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 146.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 145.9ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> chair\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 145.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 157.3ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 157.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 134.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 134.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 156.6ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> chair\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 156.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 148.2ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> chair\n",
      "Speed: 2.5ms preprocess, 148.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 154.1ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> chair\n",
      "Speed: 0.0ms preprocess, 154.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 152.3ms\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 152.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 160.6ms\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 160.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.1ms\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 145.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 145.5ms\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 145.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 128.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 128.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 159.0ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 159.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 142.7ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Speed: 8.1ms preprocess, 142.7ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 161.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Speed: 3.5ms preprocess, 161.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 162.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 4.4ms preprocess, 162.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 155.5ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 3.1ms preprocess, 155.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 134.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 134.2ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 148.8ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 148.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 126.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Speed: 1.5ms preprocess, 126.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 142.4ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Speed: 3.7ms preprocess, 142.4ms inference, 15.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 chairs, 128.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 128.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 chairs, 167.6ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> chair\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 167.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 chairs, 161.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> chair\n",
      "Confianza ---> 0.31\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 161.4ms inference, 11.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 chairs, 174.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> chair\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Speed: 0.0ms preprocess, 174.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 chairs, 161.2ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> chair\n",
      "Confianza ---> 0.31\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 161.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 chairs, 149.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 149.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 128.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 128.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 181.4ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> chair\n",
      "Speed: 0.0ms preprocess, 181.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 3 chairs, 161.1ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> chair\n",
      "Confianza ---> 0.33\n",
      "Clase --> chair\n",
      "Confianza ---> 0.32\n",
      "Clase --> chair\n",
      "Speed: 3.8ms preprocess, 161.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 3 chairs, 138.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> chair\n",
      "Confianza ---> 0.31\n",
      "Clase --> chair\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 138.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 153.2ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 153.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 chairs, 156.7ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> chair\n",
      "Confianza ---> 0.32\n",
      "Clase --> chair\n",
      "Speed: 2.1ms preprocess, 156.7ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 chairs, 146.2ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> chair\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Speed: 3.4ms preprocess, 146.2ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 166.4ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 166.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 169.6ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> chair\n",
      "Speed: 2.8ms preprocess, 169.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 chairs, 156.0ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> chair\n",
      "Confianza ---> 0.35\n",
      "Clase --> chair\n",
      "Speed: 3.8ms preprocess, 156.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 154.3ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 2.4ms preprocess, 154.3ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 chairs, 155.1ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> chair\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 1.0ms preprocess, 155.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 4 chairs, 153.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> chair\n",
      "Confianza ---> 0.36\n",
      "Clase --> chair\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 2.8ms preprocess, 153.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 142.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Speed: 4.1ms preprocess, 142.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 151.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> chair\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 151.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 141.5ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 141.5ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 157.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 157.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 141.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 141.7ms inference, 12.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 156.1ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 156.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 140.3ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 3.2ms preprocess, 140.3ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 156.0ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 156.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 158.0ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Speed: 3.3ms preprocess, 158.0ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 150.2ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 150.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 146.1ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.2ms preprocess, 146.1ms inference, 11.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 143.4ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 143.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 128.5ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 128.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 164.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 1.2ms preprocess, 164.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 139.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 139.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 146.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 146.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 151.8ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 151.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.5ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 149.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 132.2ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 132.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 138.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> chair\n",
      "Speed: 1.1ms preprocess, 138.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 135.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Speed: 2.2ms preprocess, 135.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 128.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> chair\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Speed: 3.6ms preprocess, 128.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 141.3ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> chair\n",
      "Speed: 2.6ms preprocess, 141.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 138.4ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 138.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 159.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 159.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.6ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 3.8ms preprocess, 145.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 162.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 162.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 4.0ms preprocess, 158.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 166.1ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 1.5ms preprocess, 166.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 143.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 143.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.8ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 146.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 140.4ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 140.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.0ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 158.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 161.7ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 161.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 165.4ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 165.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 130.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 130.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 157.1ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> chair\n",
      "Speed: 0.0ms preprocess, 157.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 161.4ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 161.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 162.9ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> chair\n",
      "Speed: 1.0ms preprocess, 162.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 144.8ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> chair\n",
      "Speed: 3.2ms preprocess, 144.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 155.7ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> chair\n",
      "Speed: 1.9ms preprocess, 155.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 148.4ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> chair\n",
      "Speed: 3.5ms preprocess, 148.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 162.6ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> chair\n",
      "Speed: 4.3ms preprocess, 162.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 157.9ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 157.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 127.4ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 127.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 151.8ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 151.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 161.6ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 161.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 155.6ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 155.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.7ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 144.7ms inference, 13.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 150.3ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 150.3ms inference, 8.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 132.5ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 132.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 160.8ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> chair\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 160.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 128.9ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> chair\n",
      "Speed: 4.9ms preprocess, 128.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 141.0ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> chair\n",
      "Speed: 2.1ms preprocess, 141.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 155.0ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> chair\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 155.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 152.0ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> chair\n",
      "Speed: 1.3ms preprocess, 152.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 158.6ms\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> chair\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 158.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 145.9ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> chair\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 145.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 166.2ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 166.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 chair, 143.6ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> chair\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 2.8ms preprocess, 143.6ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 159.1ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> chair\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 159.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 154.0ms\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 0.0ms preprocess, 154.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 150.7ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 150.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 162.0ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> chair\n",
      "Speed: 3.4ms preprocess, 162.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 148.6ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 148.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 154.0ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> chair\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.1ms preprocess, 154.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 169.2ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> chair\n",
      "Speed: 1.3ms preprocess, 169.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 154.7ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 1.1ms preprocess, 154.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 165.0ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> chair\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 165.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 166.4ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> chair\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 166.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 144.0ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> chair\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.0ms preprocess, 144.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 154.7ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> chair\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 154.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 136.2ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 136.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 144.3ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 144.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 154.2ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 154.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 154.7ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> chair\n",
      "Speed: 2.1ms preprocess, 154.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 153.4ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> chair\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 4.3ms preprocess, 153.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 142.1ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> chair\n",
      "Speed: 2.4ms preprocess, 142.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 169.4ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> chair\n",
      "Speed: 0.0ms preprocess, 169.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 151.0ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> chair\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 3.6ms preprocess, 151.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 133.0ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> chair\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.9ms preprocess, 133.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 156.7ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Speed: 1.9ms preprocess, 156.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 142.4ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> chair\n",
      "Speed: 4.0ms preprocess, 142.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 148.1ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 148.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 150.7ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> chair\n",
      "Speed: 3.6ms preprocess, 150.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 158.7ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> chair\n",
      "Speed: 1.1ms preprocess, 158.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 169.0ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Speed: 3.6ms preprocess, 169.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 131.5ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> chair\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 131.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 148.1ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> chair\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 3.1ms preprocess, 148.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 136.6ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 136.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 127.0ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 3.5ms preprocess, 127.0ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 146.1ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> chair\n",
      "Speed: 3.8ms preprocess, 146.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 147.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Speed: 3.7ms preprocess, 147.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 130.4ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 130.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 158.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 158.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.0ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 158.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 155.1ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 155.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 162.2ms\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> chair\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 162.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 148.5ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 148.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.0ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 131.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 123.4ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 123.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 146.5ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 146.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 155.1ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 155.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 155.2ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> chair\n",
      "Speed: 3.3ms preprocess, 155.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 153.8ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 153.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 149.7ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Speed: 2.4ms preprocess, 149.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 133.6ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 133.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 135.3ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Speed: 2.1ms preprocess, 135.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 154.9ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 154.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 164.1ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> chair\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 164.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 165.8ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> chair\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 4.1ms preprocess, 165.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 127.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 127.8ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 153.9ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 153.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 138.7ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 138.7ms inference, 16.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 215.2ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 215.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 138.8ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> chair\n",
      "Speed: 3.4ms preprocess, 138.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 164.7ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> chair\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 164.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 150.5ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> chair\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.2ms preprocess, 150.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 132.5ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> chair\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 132.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 159.0ms\n",
      "Confianza ---> 0.56\n",
      "Clase --> chair\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Speed: 2.8ms preprocess, 159.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 164.3ms\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> chair\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 164.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 chairs, 127.8ms\n",
      "Confianza ---> 0.59\n",
      "Clase --> chair\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> chair\n",
      "Speed: 2.5ms preprocess, 127.8ms inference, 13.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 153.5ms\n",
      "Confianza ---> 0.5\n",
      "Clase --> chair\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 153.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 chairs, 1 cell phone, 155.3ms\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> chair\n",
      "Confianza ---> 0.42\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Speed: 2.5ms preprocess, 155.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 chair, 136.4ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> chair\n",
      "Speed: 3.4ms preprocess, 136.4ms inference, 13.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 chair, 146.1ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> chair\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 146.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 148.1ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 148.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 168.8ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> chair\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 168.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 120.8ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> chair\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 120.8ms inference, 15.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 151.0ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> chair\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 151.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 155.1ms\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> chair\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 0.0ms preprocess, 155.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 163.6ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> chair\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 163.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 160.9ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> chair\n",
      "Speed: 1.9ms preprocess, 160.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 149.2ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> chair\n",
      "Speed: 3.3ms preprocess, 149.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 156.3ms\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Speed: 1.6ms preprocess, 156.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 171.9ms\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> chair\n",
      "Speed: 3.7ms preprocess, 171.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 161.4ms\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 161.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 131.2ms\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 131.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 147.2ms\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Speed: 0.9ms preprocess, 147.2ms inference, 15.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 139.4ms\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 139.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 156.4ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 156.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 128.3ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 128.3ms inference, 16.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 141.4ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 141.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 144.0ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> chair\n",
      "Speed: 2.4ms preprocess, 144.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 151.6ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> chair\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 151.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 159.7ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> chair\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 159.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 149.6ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Speed: 3.9ms preprocess, 149.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 158.4ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 158.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 161.7ms\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> chair\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 161.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 161.3ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> chair\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 161.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 159.7ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> chair\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 159.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 157.5ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> chair\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 3.1ms preprocess, 157.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 129.1ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 129.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.2ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 141.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 135.4ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> chair\n",
      "Speed: 3.8ms preprocess, 135.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 161.6ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> chair\n",
      "Speed: 2.8ms preprocess, 161.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 148.8ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> chair\n",
      "Speed: 3.4ms preprocess, 148.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 164.6ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> chair\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 164.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 149.4ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> chair\n",
      "Speed: 1.6ms preprocess, 149.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 131.5ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> chair\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 1.3ms preprocess, 131.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 157.7ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Speed: 4.1ms preprocess, 157.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 160.1ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 3.1ms preprocess, 160.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 153.1ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> chair\n",
      "Speed: 1.6ms preprocess, 153.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 165.1ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 165.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 139.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> chair\n",
      "Speed: 8.2ms preprocess, 139.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 163.9ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> chair\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 163.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 160.6ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 160.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 157.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 157.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 166.9ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 166.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 144.5ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> chair\n",
      "Speed: 1.0ms preprocess, 144.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 171.3ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 171.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 182.3ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> chair\n",
      "Speed: 0.0ms preprocess, 182.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 174.1ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> chair\n",
      "Speed: 2.1ms preprocess, 174.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 167.2ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 167.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 155.1ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> chair\n",
      "Speed: 1.9ms preprocess, 155.1ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 153.6ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 153.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 161.6ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> chair\n",
      "Speed: 3.4ms preprocess, 161.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 187.6ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> chair\n",
      "Speed: 2.4ms preprocess, 187.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 168.7ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> chair\n",
      "Speed: 3.0ms preprocess, 168.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 153.8ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> chair\n",
      "Speed: 3.6ms preprocess, 153.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 178.2ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> chair\n",
      "Speed: 2.3ms preprocess, 178.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 183.3ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> chair\n",
      "Speed: 3.2ms preprocess, 183.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 138.6ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> chair\n",
      "Speed: 1.7ms preprocess, 138.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 171.9ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> chair\n",
      "Speed: 2.5ms preprocess, 171.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 156.6ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> chair\n",
      "Speed: 0.0ms preprocess, 156.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 201.4ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 201.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 160.3ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> chair\n",
      "Confianza ---> 0.34\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 160.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 150.5ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> chair\n",
      "Confianza ---> 0.35\n",
      "Clase --> chair\n",
      "Speed: 1.9ms preprocess, 150.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 171.0ms\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> chair\n",
      "Confianza ---> 0.37\n",
      "Clase --> chair\n",
      "Speed: 0.5ms preprocess, 171.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 161.9ms\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> chair\n",
      "Confianza ---> 0.28\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 161.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 159.0ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> chair\n",
      "Speed: 2.5ms preprocess, 159.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo, descarga en disco si no está presente en la carpeta\n",
    "model = YOLO('YOLO/yolo11n.pt') #Contenedores\n",
    "\n",
    "# Etiqueta de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "\n",
    "# Captura desde la webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen válida\n",
    "    if ret:  \n",
    "        # Detecta en la imagen\n",
    "        results = model(img, stream=True)\n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confianza --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Clase -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador numérico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimiento. Requiere instalar lap con pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 177.6ms\n",
      "Speed: 3.0ms preprocess, 177.6ms inference, 18.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 226.8ms\n",
      "Speed: 5.0ms preprocess, 226.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 143.1ms\n",
      "Speed: 0.0ms preprocess, 143.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 142.6ms\n",
      "Speed: 0.0ms preprocess, 142.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 176.9ms\n",
      "Speed: 2.3ms preprocess, 176.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 145.3ms\n",
      "Speed: 2.1ms preprocess, 145.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 142.6ms\n",
      "Speed: 3.0ms preprocess, 142.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 157.6ms\n",
      "Speed: 3.2ms preprocess, 157.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 147.8ms\n",
      "Speed: 2.0ms preprocess, 147.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 129.9ms\n",
      "Speed: 2.0ms preprocess, 129.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 142.8ms\n",
      "Speed: 3.0ms preprocess, 142.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 160.9ms\n",
      "Speed: 2.0ms preprocess, 160.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 143.1ms\n",
      "Speed: 2.0ms preprocess, 143.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 141.1ms\n",
      "Speed: 1.0ms preprocess, 141.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 128.8ms\n",
      "Speed: 3.5ms preprocess, 128.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 148.9ms\n",
      "Speed: 2.0ms preprocess, 148.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 149.6ms\n",
      "Speed: 3.2ms preprocess, 149.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 146.2ms\n",
      "Speed: 2.3ms preprocess, 146.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 158.6ms\n",
      "Speed: 0.0ms preprocess, 158.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 128.8ms\n",
      "Speed: 2.0ms preprocess, 128.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 159.5ms\n",
      "Speed: 2.0ms preprocess, 159.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 150.3ms\n",
      "Speed: 2.1ms preprocess, 150.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 137.5ms\n",
      "Speed: 1.0ms preprocess, 137.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 162.1ms\n",
      "Speed: 2.1ms preprocess, 162.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 160.8ms\n",
      "Speed: 2.4ms preprocess, 160.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 161.8ms\n",
      "Speed: 2.0ms preprocess, 161.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 160.6ms\n",
      "Speed: 2.0ms preprocess, 160.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 165.6ms\n",
      "Speed: 2.7ms preprocess, 165.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 154.4ms\n",
      "Speed: 2.5ms preprocess, 154.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 157.5ms\n",
      "Speed: 2.0ms preprocess, 157.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 144.7ms\n",
      "Speed: 1.4ms preprocess, 144.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 160.8ms\n",
      "Speed: 2.0ms preprocess, 160.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 147.8ms\n",
      "Speed: 2.0ms preprocess, 147.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 145.1ms\n",
      "Speed: 1.1ms preprocess, 145.1ms inference, 17.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 150.5ms\n",
      "Speed: 2.0ms preprocess, 150.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 134.3ms\n",
      "Speed: 2.0ms preprocess, 134.3ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 150.7ms\n",
      "Speed: 2.0ms preprocess, 150.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 159.8ms\n",
      "Speed: 1.1ms preprocess, 159.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 123.3ms\n",
      "Speed: 2.0ms preprocess, 123.3ms inference, 21.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 154.2ms\n",
      "Speed: 1.1ms preprocess, 154.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 147.7ms\n",
      "Speed: 2.1ms preprocess, 147.7ms inference, 12.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 159.0ms\n",
      "Speed: 1.0ms preprocess, 159.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 158.5ms\n",
      "Speed: 1.0ms preprocess, 158.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 164.9ms\n",
      "Speed: 2.5ms preprocess, 164.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 160.7ms\n",
      "Speed: 2.0ms preprocess, 160.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 180.3ms\n",
      "Speed: 2.7ms preprocess, 180.3ms inference, 17.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 132.5ms\n",
      "Speed: 1.8ms preprocess, 132.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 155.5ms\n",
      "Speed: 2.4ms preprocess, 155.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 162.7ms\n",
      "Speed: 1.9ms preprocess, 162.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 154.1ms\n",
      "Speed: 0.6ms preprocess, 154.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 154.2ms\n",
      "Speed: 2.4ms preprocess, 154.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 154.5ms\n",
      "Speed: 2.4ms preprocess, 154.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 151.4ms\n",
      "Speed: 2.2ms preprocess, 151.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 161.4ms\n",
      "Speed: 2.1ms preprocess, 161.4ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 138.2ms\n",
      "Speed: 2.1ms preprocess, 138.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 160.8ms\n",
      "Speed: 3.3ms preprocess, 160.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 156.9ms\n",
      "Speed: 11.4ms preprocess, 156.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 147.3ms\n",
      "Speed: 3.0ms preprocess, 147.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 144.8ms\n",
      "Speed: 1.0ms preprocess, 144.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 166.2ms\n",
      "Speed: 3.0ms preprocess, 166.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 151.9ms\n",
      "Speed: 2.7ms preprocess, 151.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 130.3ms\n",
      "Speed: 3.0ms preprocess, 130.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 154.6ms\n",
      "Speed: 2.0ms preprocess, 154.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 132.9ms\n",
      "Speed: 2.5ms preprocess, 132.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 154.1ms\n",
      "Speed: 2.6ms preprocess, 154.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 145.3ms\n",
      "Speed: 3.1ms preprocess, 145.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 158.0ms\n",
      "Speed: 2.4ms preprocess, 158.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 148.6ms\n",
      "Speed: 1.0ms preprocess, 148.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 129.2ms\n",
      "Speed: 2.0ms preprocess, 129.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 145.8ms\n",
      "Speed: 2.0ms preprocess, 145.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 160.8ms\n",
      "Speed: 2.2ms preprocess, 160.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 125.9ms\n",
      "Speed: 4.0ms preprocess, 125.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 159.3ms\n",
      "Speed: 1.2ms preprocess, 159.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 146.3ms\n",
      "Speed: 3.0ms preprocess, 146.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 141.7ms\n",
      "Speed: 2.1ms preprocess, 141.7ms inference, 15.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 145.7ms\n",
      "Speed: 2.0ms preprocess, 145.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 152.2ms\n",
      "Speed: 3.0ms preprocess, 152.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 159.6ms\n",
      "Speed: 2.0ms preprocess, 159.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 154.1ms\n",
      "Speed: 2.0ms preprocess, 154.1ms inference, 8.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 158.4ms\n",
      "Speed: 3.0ms preprocess, 158.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 147.4ms\n",
      "Speed: 2.0ms preprocess, 147.4ms inference, 11.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 156.2ms\n",
      "Speed: 3.0ms preprocess, 156.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 157.9ms\n",
      "Speed: 1.9ms preprocess, 157.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 161.4ms\n",
      "Speed: 1.5ms preprocess, 161.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 144.7ms\n",
      "Speed: 3.0ms preprocess, 144.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 158.0ms\n",
      "Speed: 2.0ms preprocess, 158.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 158.0ms\n",
      "Speed: 2.0ms preprocess, 158.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 157.2ms\n",
      "Speed: 2.0ms preprocess, 157.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 140.2ms\n",
      "Speed: 2.0ms preprocess, 140.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 137.0ms\n",
      "Speed: 4.0ms preprocess, 137.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 131.7ms\n",
      "Speed: 2.0ms preprocess, 131.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 140.3ms\n",
      "Speed: 2.1ms preprocess, 140.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 133.5ms\n",
      "Speed: 3.0ms preprocess, 133.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 130.8ms\n",
      "Speed: 2.0ms preprocess, 130.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 163.5ms\n",
      "Speed: 0.0ms preprocess, 163.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 136.4ms\n",
      "Speed: 2.0ms preprocess, 136.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 171.5ms\n",
      "Speed: 2.0ms preprocess, 171.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 123.0ms\n",
      "Speed: 2.7ms preprocess, 123.0ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 160.7ms\n",
      "Speed: 0.0ms preprocess, 160.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 154.6ms\n",
      "Speed: 1.5ms preprocess, 154.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 152.4ms\n",
      "Speed: 3.2ms preprocess, 152.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 155.0ms\n",
      "Speed: 2.4ms preprocess, 155.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 158.7ms\n",
      "Speed: 2.0ms preprocess, 158.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 123.7ms\n",
      "Speed: 2.0ms preprocess, 123.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 150.1ms\n",
      "Speed: 2.0ms preprocess, 150.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 152.7ms\n",
      "Speed: 1.6ms preprocess, 152.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 147.9ms\n",
      "Speed: 2.0ms preprocess, 147.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 151.1ms\n",
      "Speed: 1.0ms preprocess, 151.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 155.6ms\n",
      "Speed: 2.0ms preprocess, 155.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 187.5ms\n",
      "Speed: 3.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 139.6ms\n",
      "Speed: 2.0ms preprocess, 139.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 155.5ms\n",
      "Speed: 2.4ms preprocess, 155.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 148.5ms\n",
      "Speed: 2.0ms preprocess, 148.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 121.7ms\n",
      "Speed: 2.6ms preprocess, 121.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 160.9ms\n",
      "Speed: 0.0ms preprocess, 160.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 151.9ms\n",
      "Speed: 4.2ms preprocess, 151.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 158.2ms\n",
      "Speed: 2.0ms preprocess, 158.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 154.6ms\n",
      "Speed: 1.9ms preprocess, 154.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 158.6ms\n",
      "Speed: 2.0ms preprocess, 158.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 154.4ms\n",
      "Speed: 2.0ms preprocess, 154.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 151.2ms\n",
      "Speed: 2.0ms preprocess, 151.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 183.0ms\n",
      "Speed: 2.3ms preprocess, 183.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 150.7ms\n",
      "Speed: 2.0ms preprocess, 150.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 145.2ms\n",
      "Speed: 1.6ms preprocess, 145.2ms inference, 12.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 120.5ms\n",
      "Speed: 2.0ms preprocess, 120.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 146.2ms\n",
      "Speed: 0.0ms preprocess, 146.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 150.8ms\n",
      "Speed: 2.0ms preprocess, 150.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 143.7ms\n",
      "Speed: 3.0ms preprocess, 143.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 156.9ms\n",
      "Speed: 0.0ms preprocess, 156.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 146.5ms\n",
      "Speed: 3.0ms preprocess, 146.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 129.5ms\n",
      "Speed: 2.0ms preprocess, 129.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 151.3ms\n",
      "Speed: 0.0ms preprocess, 151.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 154.5ms\n",
      "Speed: 3.2ms preprocess, 154.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 135.7ms\n",
      "Speed: 3.0ms preprocess, 135.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 162.7ms\n",
      "Speed: 2.0ms preprocess, 162.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 153.3ms\n",
      "Speed: 3.0ms preprocess, 153.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 156.8ms\n",
      "Speed: 2.5ms preprocess, 156.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 156.3ms\n",
      "Speed: 0.8ms preprocess, 156.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 151.0ms\n",
      "Speed: 2.6ms preprocess, 151.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 156.5ms\n",
      "Speed: 1.9ms preprocess, 156.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 137.8ms\n",
      "Speed: 2.1ms preprocess, 137.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 157.9ms\n",
      "Speed: 2.0ms preprocess, 157.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 138.5ms\n",
      "Speed: 2.0ms preprocess, 138.5ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 134.8ms\n",
      "Speed: 3.0ms preprocess, 134.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 153.6ms\n",
      "Speed: 2.0ms preprocess, 153.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 132.2ms\n",
      "Speed: 4.0ms preprocess, 132.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 159.6ms\n",
      "Speed: 2.0ms preprocess, 159.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 158.7ms\n",
      "Speed: 1.0ms preprocess, 158.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 164.1ms\n",
      "Speed: 2.0ms preprocess, 164.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 130.7ms\n",
      "Speed: 2.0ms preprocess, 130.7ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 151.3ms\n",
      "Speed: 3.7ms preprocess, 151.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 155.1ms\n",
      "Speed: 2.0ms preprocess, 155.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 138.7ms\n",
      "Speed: 1.3ms preprocess, 138.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 162.4ms\n",
      "Speed: 2.0ms preprocess, 162.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 157.5ms\n",
      "Speed: 2.0ms preprocess, 157.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 163.2ms\n",
      "Speed: 2.5ms preprocess, 163.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 143.7ms\n",
      "Speed: 4.1ms preprocess, 143.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 163.1ms\n",
      "Speed: 2.1ms preprocess, 163.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 129.2ms\n",
      "Speed: 2.0ms preprocess, 129.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 154.7ms\n",
      "Speed: 3.0ms preprocess, 154.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 163.0ms\n",
      "Speed: 2.0ms preprocess, 163.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 145.4ms\n",
      "Speed: 2.0ms preprocess, 145.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 158.7ms\n",
      "Speed: 2.0ms preprocess, 158.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 150.3ms\n",
      "Speed: 11.7ms preprocess, 150.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 160.3ms\n",
      "Speed: 4.0ms preprocess, 160.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 164.1ms\n",
      "Speed: 0.7ms preprocess, 164.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 130.2ms\n",
      "Speed: 2.0ms preprocess, 130.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 158.2ms\n",
      "Speed: 2.0ms preprocess, 158.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 161.3ms\n",
      "Speed: 2.3ms preprocess, 161.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 162.9ms\n",
      "Speed: 1.6ms preprocess, 162.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 154.8ms\n",
      "Speed: 2.0ms preprocess, 154.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 154.2ms\n",
      "Speed: 2.0ms preprocess, 154.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 156.2ms\n",
      "Speed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 121.8ms\n",
      "Speed: 2.5ms preprocess, 121.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 141.7ms\n",
      "Speed: 2.0ms preprocess, 141.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 149.8ms\n",
      "Speed: 11.1ms preprocess, 149.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 168.2ms\n",
      "Speed: 3.0ms preprocess, 168.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 151.2ms\n",
      "Speed: 2.0ms preprocess, 151.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 151.8ms\n",
      "Speed: 2.1ms preprocess, 151.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 131.7ms\n",
      "Speed: 2.0ms preprocess, 131.7ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 141.5ms\n",
      "Speed: 2.5ms preprocess, 141.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 150.3ms\n",
      "Speed: 2.0ms preprocess, 150.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 164.4ms\n",
      "Speed: 2.4ms preprocess, 164.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 156.0ms\n",
      "Speed: 2.0ms preprocess, 156.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 135.2ms\n",
      "Speed: 0.0ms preprocess, 135.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 137.8ms\n",
      "Speed: 2.0ms preprocess, 137.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 147.6ms\n",
      "Speed: 0.0ms preprocess, 147.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 129.8ms\n",
      "Speed: 2.0ms preprocess, 129.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 129.4ms\n",
      "Speed: 3.0ms preprocess, 129.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 148.5ms\n",
      "Speed: 2.0ms preprocess, 148.5ms inference, 15.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 157.5ms\n",
      "Speed: 2.1ms preprocess, 157.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 135.5ms\n",
      "Speed: 2.0ms preprocess, 135.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 160.0ms\n",
      "Speed: 2.0ms preprocess, 160.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 129.4ms\n",
      "Speed: 0.0ms preprocess, 129.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 153.2ms\n",
      "Speed: 1.0ms preprocess, 153.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 151.0ms\n",
      "Speed: 2.7ms preprocess, 151.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 151.7ms\n",
      "Speed: 2.0ms preprocess, 151.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 147.5ms\n",
      "Speed: 3.0ms preprocess, 147.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 152.0ms\n",
      "Speed: 1.0ms preprocess, 152.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 129.4ms\n",
      "Speed: 2.4ms preprocess, 129.4ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 151.4ms\n",
      "Speed: 2.0ms preprocess, 151.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 129.7ms\n",
      "Speed: 2.0ms preprocess, 129.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 142.9ms\n",
      "Speed: 1.7ms preprocess, 142.9ms inference, 15.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 128.9ms\n",
      "Speed: 3.7ms preprocess, 128.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 156.3ms\n",
      "Speed: 3.8ms preprocess, 156.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 157.5ms\n",
      "Speed: 2.0ms preprocess, 157.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 148.4ms\n",
      "Speed: 2.0ms preprocess, 148.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 151.1ms\n",
      "Speed: 0.0ms preprocess, 151.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 129.3ms\n",
      "Speed: 2.0ms preprocess, 129.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 138.1ms\n",
      "Speed: 2.5ms preprocess, 138.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.12\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 151.1ms\n",
      "Speed: 2.0ms preprocess, 151.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 150.6ms\n",
      "Speed: 2.5ms preprocess, 150.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 151.8ms\n",
      "Speed: 3.1ms preprocess, 151.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 152.2ms\n",
      "Speed: 0.0ms preprocess, 152.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 135.6ms\n",
      "Speed: 2.0ms preprocess, 135.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 155.6ms\n",
      "Speed: 3.2ms preprocess, 155.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 143.1ms\n",
      "Speed: 4.0ms preprocess, 143.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 148.3ms\n",
      "Speed: 2.0ms preprocess, 148.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 144.0ms\n",
      "Speed: 3.0ms preprocess, 144.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 3 persons, 151.4ms\n",
      "Speed: 3.0ms preprocess, 151.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 2 persons, 157.3ms\n",
      "Speed: 2.0ms preprocess, 157.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 158.4ms\n",
      "Speed: 2.2ms preprocess, 158.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 147.7ms\n",
      "Speed: 2.0ms preprocess, 147.7ms inference, 8.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 138.4ms\n",
      "Speed: 2.0ms preprocess, 138.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 129.3ms\n",
      "Speed: 1.0ms preprocess, 129.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 156.2ms\n",
      "Speed: 3.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 154.0ms\n",
      "Speed: 2.0ms preprocess, 154.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 144.8ms\n",
      "Speed: 3.0ms preprocess, 144.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 132.2ms\n",
      "Speed: 2.0ms preprocess, 132.2ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 129.5ms\n",
      "Speed: 3.0ms preprocess, 129.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 155.8ms\n",
      "Speed: 2.5ms preprocess, 155.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 146.0ms\n",
      "Speed: 2.0ms preprocess, 146.0ms inference, 12.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 159.1ms\n",
      "Speed: 2.0ms preprocess, 159.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 129.0ms\n",
      "Speed: 3.0ms preprocess, 129.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 130.2ms\n",
      "Speed: 3.0ms preprocess, 130.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 152.1ms\n",
      "Speed: 2.0ms preprocess, 152.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 157.3ms\n",
      "Speed: 2.0ms preprocess, 157.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 145.3ms\n",
      "Speed: 2.0ms preprocess, 145.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 149.9ms\n",
      "Speed: 1.6ms preprocess, 149.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 146.5ms\n",
      "Speed: 2.0ms preprocess, 146.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 148.2ms\n",
      "Speed: 3.0ms preprocess, 148.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 143.2ms\n",
      "Speed: 2.1ms preprocess, 143.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 156.7ms\n",
      "Speed: 2.6ms preprocess, 156.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 149.9ms\n",
      "Speed: 2.4ms preprocess, 149.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 131.3ms\n",
      "Speed: 2.0ms preprocess, 131.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 155.5ms\n",
      "Speed: 2.0ms preprocess, 155.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 158.6ms\n",
      "Speed: 2.0ms preprocess, 158.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 158.2ms\n",
      "Speed: 4.4ms preprocess, 158.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 147.8ms\n",
      "Speed: 3.5ms preprocess, 147.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "\n",
      "0: 480x640 1 person, 155.4ms\n",
      "Speed: 2.0ms preprocess, 155.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Carga del modelo, descarga en disco si no está presente en la carpeta\n",
    "model = YOLO('YOLO/yolo11n.pt') #Contenedores\n",
    "\n",
    "# Etiqueta de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\"]\n",
    "\n",
    "\n",
    "# Captura desde la webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "track_history = defaultdict(lambda: [])\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen válida\n",
    "    if ret:  \n",
    "        # Seguimiento, con persistencia entre fotogramas\n",
    "        results = model.track(img, persist=True, classes = [0,1,2])\n",
    "\n",
    "        if 0:\n",
    "            if results is not None:\n",
    "                print(results[0])\n",
    "                boxes = results[0].boxes.xywh.cpu()\n",
    "                track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "                annotated_frame = results[0].plot()\n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    x, y, w, h = box\n",
    "                    track = track_history[track_id]\n",
    "                    track.append((float(x), float(y)))\n",
    "                    if len(track) > 30:\n",
    "                        track.pop(0)\n",
    "                    points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                    cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "                cv2.imshow(\"YOLO11 Tracking\", annotated_frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "        \n",
    "\n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "                #Etiqueta de seguimiento\n",
    "                if box.id is not None:\n",
    "                    track_id = str(int(box.id[0].tolist()))\n",
    "                else:\n",
    "                    track_id = ''\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confianza --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Clase -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador numérico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, track_id + ' ' + classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intregración con seguimiento (tracking)\n",
    "!!!!!!!!!Nota: he tenido que bajar a la versión de python 3.9.5 e instalar lap con pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'YOLO\\yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 6.87MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 135.7ms\n",
      "video 1/1 (frame 2/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 214.9ms\n",
      "video 1/1 (frame 3/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 135.5ms\n",
      "video 1/1 (frame 4/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 132.6ms\n",
      "video 1/1 (frame 5/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 150.6ms\n",
      "video 1/1 (frame 6/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 140.0ms\n",
      "video 1/1 (frame 7/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 128.1ms\n",
      "video 1/1 (frame 8/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 127.4ms\n",
      "video 1/1 (frame 9/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 121.5ms\n",
      "video 1/1 (frame 10/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 134.1ms\n",
      "video 1/1 (frame 11/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 5 persons, 1 bird, 130.7ms\n",
      "video 1/1 (frame 12/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 5 persons, 1 bird, 138.8ms\n",
      "video 1/1 (frame 13/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 134.7ms\n",
      "video 1/1 (frame 14/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 139.2ms\n",
      "video 1/1 (frame 15/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 131.6ms\n",
      "video 1/1 (frame 16/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 4 persons, 1 bird, 130.8ms\n",
      "video 1/1 (frame 17/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 141.1ms\n",
      "video 1/1 (frame 18/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 117.4ms\n",
      "video 1/1 (frame 19/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 117.5ms\n",
      "video 1/1 (frame 20/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 121.9ms\n",
      "video 1/1 (frame 21/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 126.7ms\n",
      "video 1/1 (frame 22/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 128.8ms\n",
      "video 1/1 (frame 23/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 131.7ms\n",
      "video 1/1 (frame 24/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 114.6ms\n",
      "video 1/1 (frame 25/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 122.6ms\n",
      "video 1/1 (frame 26/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 111.6ms\n",
      "video 1/1 (frame 27/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 112.2ms\n",
      "video 1/1 (frame 28/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 124.1ms\n",
      "video 1/1 (frame 29/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 118.7ms\n",
      "video 1/1 (frame 30/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 137.5ms\n",
      "video 1/1 (frame 31/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 132.9ms\n",
      "video 1/1 (frame 32/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 121.7ms\n",
      "video 1/1 (frame 33/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 113.1ms\n",
      "video 1/1 (frame 34/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 150.7ms\n",
      "video 1/1 (frame 35/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 120.0ms\n",
      "video 1/1 (frame 36/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 124.9ms\n",
      "video 1/1 (frame 37/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 123.9ms\n",
      "video 1/1 (frame 38/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 123.5ms\n",
      "video 1/1 (frame 39/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 118.8ms\n",
      "video 1/1 (frame 40/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 111.8ms\n",
      "video 1/1 (frame 41/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 131.3ms\n",
      "video 1/1 (frame 42/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 125.6ms\n",
      "video 1/1 (frame 43/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 107.3ms\n",
      "video 1/1 (frame 44/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 135.2ms\n",
      "video 1/1 (frame 45/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 128.6ms\n",
      "video 1/1 (frame 46/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 125.8ms\n",
      "video 1/1 (frame 47/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 132.4ms\n",
      "video 1/1 (frame 48/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 130.6ms\n",
      "video 1/1 (frame 49/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 114.9ms\n",
      "video 1/1 (frame 50/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 140.1ms\n",
      "video 1/1 (frame 51/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 127.8ms\n",
      "video 1/1 (frame 52/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 120.2ms\n",
      "video 1/1 (frame 53/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 115.3ms\n",
      "video 1/1 (frame 54/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 124.7ms\n",
      "video 1/1 (frame 55/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 142.6ms\n",
      "video 1/1 (frame 56/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 113.7ms\n",
      "video 1/1 (frame 57/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 129.4ms\n",
      "video 1/1 (frame 58/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 146.1ms\n",
      "video 1/1 (frame 59/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 162.6ms\n",
      "video 1/1 (frame 60/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 126.4ms\n",
      "video 1/1 (frame 61/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 137.7ms\n",
      "video 1/1 (frame 62/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 128.1ms\n",
      "video 1/1 (frame 63/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 168.6ms\n",
      "video 1/1 (frame 64/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 124.7ms\n",
      "video 1/1 (frame 65/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 131.6ms\n",
      "video 1/1 (frame 66/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 119.4ms\n",
      "video 1/1 (frame 67/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 130.9ms\n",
      "video 1/1 (frame 68/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 124.4ms\n",
      "video 1/1 (frame 69/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 132.6ms\n",
      "video 1/1 (frame 70/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 121.6ms\n",
      "video 1/1 (frame 71/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 133.7ms\n",
      "video 1/1 (frame 72/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 143.7ms\n",
      "video 1/1 (frame 73/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 144.5ms\n",
      "video 1/1 (frame 74/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 127.8ms\n",
      "video 1/1 (frame 75/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 128.9ms\n",
      "video 1/1 (frame 76/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 133.3ms\n",
      "video 1/1 (frame 77/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 133.3ms\n",
      "video 1/1 (frame 78/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 133.7ms\n",
      "video 1/1 (frame 79/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 133.4ms\n",
      "video 1/1 (frame 80/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 127.6ms\n",
      "video 1/1 (frame 81/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 153.8ms\n",
      "video 1/1 (frame 82/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 152.0ms\n",
      "video 1/1 (frame 83/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 150.2ms\n",
      "video 1/1 (frame 84/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 131.7ms\n",
      "video 1/1 (frame 85/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 150.0ms\n",
      "video 1/1 (frame 86/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 123.5ms\n",
      "video 1/1 (frame 87/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 128.6ms\n",
      "video 1/1 (frame 88/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 130.6ms\n",
      "video 1/1 (frame 89/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 132.1ms\n",
      "video 1/1 (frame 90/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 127.2ms\n",
      "video 1/1 (frame 91/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 131.9ms\n",
      "video 1/1 (frame 92/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 132.4ms\n",
      "video 1/1 (frame 93/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 130.0ms\n",
      "video 1/1 (frame 94/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 127.3ms\n",
      "video 1/1 (frame 95/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 134.4ms\n",
      "video 1/1 (frame 96/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 112.9ms\n",
      "video 1/1 (frame 97/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 145.3ms\n",
      "video 1/1 (frame 98/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 120.5ms\n",
      "video 1/1 (frame 99/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 117.4ms\n",
      "video 1/1 (frame 100/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 131.9ms\n",
      "video 1/1 (frame 101/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 135.1ms\n",
      "video 1/1 (frame 102/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 133.8ms\n",
      "video 1/1 (frame 103/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 146.3ms\n",
      "video 1/1 (frame 104/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 140.7ms\n",
      "video 1/1 (frame 105/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 134.1ms\n",
      "video 1/1 (frame 106/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 131.1ms\n",
      "video 1/1 (frame 107/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 125.5ms\n",
      "video 1/1 (frame 108/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 132.4ms\n",
      "video 1/1 (frame 109/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 126.9ms\n",
      "video 1/1 (frame 110/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 132.9ms\n",
      "video 1/1 (frame 111/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 116.3ms\n",
      "video 1/1 (frame 112/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 117.2ms\n",
      "video 1/1 (frame 113/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 116.4ms\n",
      "video 1/1 (frame 114/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 135.7ms\n",
      "video 1/1 (frame 115/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 122.9ms\n",
      "video 1/1 (frame 116/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 134.3ms\n",
      "video 1/1 (frame 117/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 145.6ms\n",
      "video 1/1 (frame 118/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 124.5ms\n",
      "video 1/1 (frame 119/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 120.9ms\n",
      "video 1/1 (frame 120/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 121.9ms\n",
      "video 1/1 (frame 121/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 119.7ms\n",
      "video 1/1 (frame 122/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 118.8ms\n",
      "video 1/1 (frame 123/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 139.3ms\n",
      "video 1/1 (frame 124/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 141.1ms\n",
      "video 1/1 (frame 125/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 136.0ms\n",
      "video 1/1 (frame 126/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 123.4ms\n",
      "video 1/1 (frame 127/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 118.4ms\n",
      "video 1/1 (frame 128/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 136.5ms\n",
      "video 1/1 (frame 129/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 125.9ms\n",
      "video 1/1 (frame 130/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 133.6ms\n",
      "video 1/1 (frame 131/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 141.4ms\n",
      "video 1/1 (frame 132/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 125.5ms\n",
      "video 1/1 (frame 133/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 128.8ms\n",
      "video 1/1 (frame 134/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 127.4ms\n",
      "video 1/1 (frame 135/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 130.4ms\n",
      "video 1/1 (frame 136/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 142.7ms\n",
      "video 1/1 (frame 137/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 107.5ms\n",
      "video 1/1 (frame 138/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 133.7ms\n",
      "video 1/1 (frame 139/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 124.7ms\n",
      "video 1/1 (frame 140/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 118.5ms\n",
      "video 1/1 (frame 141/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 127.5ms\n",
      "video 1/1 (frame 142/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 138.3ms\n",
      "video 1/1 (frame 143/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 136.3ms\n",
      "video 1/1 (frame 144/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 201.8ms\n",
      "video 1/1 (frame 145/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 134.4ms\n",
      "video 1/1 (frame 146/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 134.0ms\n",
      "video 1/1 (frame 147/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 137.6ms\n",
      "video 1/1 (frame 148/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 121.8ms\n",
      "video 1/1 (frame 149/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 122.6ms\n",
      "video 1/1 (frame 150/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 131.8ms\n",
      "video 1/1 (frame 151/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 126.2ms\n",
      "video 1/1 (frame 152/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 119.1ms\n",
      "video 1/1 (frame 153/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 126.3ms\n",
      "video 1/1 (frame 154/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 121.0ms\n",
      "video 1/1 (frame 155/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 142.0ms\n",
      "video 1/1 (frame 156/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 134.1ms\n",
      "video 1/1 (frame 157/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 123.3ms\n",
      "video 1/1 (frame 158/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 116.1ms\n",
      "video 1/1 (frame 159/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 132.7ms\n",
      "video 1/1 (frame 160/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 151.7ms\n",
      "video 1/1 (frame 161/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 155.5ms\n",
      "video 1/1 (frame 162/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 144.9ms\n",
      "video 1/1 (frame 163/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 122.4ms\n",
      "video 1/1 (frame 164/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 138.6ms\n",
      "video 1/1 (frame 165/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 124.6ms\n",
      "video 1/1 (frame 166/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 118.1ms\n",
      "video 1/1 (frame 167/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 130.1ms\n",
      "video 1/1 (frame 168/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 128.5ms\n",
      "video 1/1 (frame 169/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 118.0ms\n",
      "video 1/1 (frame 170/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 112.6ms\n",
      "video 1/1 (frame 171/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 116.4ms\n",
      "video 1/1 (frame 172/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 110.7ms\n",
      "video 1/1 (frame 173/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 122.8ms\n",
      "video 1/1 (frame 174/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 107.3ms\n",
      "video 1/1 (frame 175/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 129.0ms\n",
      "video 1/1 (frame 176/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 128.7ms\n",
      "video 1/1 (frame 177/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 138.6ms\n",
      "video 1/1 (frame 178/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 146.7ms\n",
      "video 1/1 (frame 179/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 133.3ms\n",
      "video 1/1 (frame 180/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 124.7ms\n",
      "video 1/1 (frame 181/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 142.9ms\n",
      "video 1/1 (frame 182/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 131.7ms\n",
      "video 1/1 (frame 183/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 138.1ms\n",
      "video 1/1 (frame 184/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 140.8ms\n",
      "video 1/1 (frame 185/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 155.9ms\n",
      "video 1/1 (frame 186/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 137.1ms\n",
      "video 1/1 (frame 187/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 129.8ms\n",
      "video 1/1 (frame 188/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 146.6ms\n",
      "video 1/1 (frame 189/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 131.9ms\n",
      "video 1/1 (frame 190/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 138.4ms\n",
      "video 1/1 (frame 191/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 135.2ms\n",
      "video 1/1 (frame 192/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 152.6ms\n",
      "video 1/1 (frame 193/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 123.8ms\n",
      "video 1/1 (frame 194/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 128.4ms\n",
      "video 1/1 (frame 195/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 horse, 124.2ms\n",
      "video 1/1 (frame 196/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 horse, 133.2ms\n",
      "video 1/1 (frame 197/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 117.7ms\n",
      "video 1/1 (frame 198/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 126.4ms\n",
      "video 1/1 (frame 199/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 151.5ms\n",
      "video 1/1 (frame 200/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 126.1ms\n",
      "video 1/1 (frame 201/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 horse, 121.5ms\n",
      "video 1/1 (frame 202/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 122.3ms\n",
      "video 1/1 (frame 203/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 116.2ms\n",
      "video 1/1 (frame 204/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 121.0ms\n",
      "video 1/1 (frame 205/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 141.0ms\n",
      "video 1/1 (frame 206/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 130.8ms\n",
      "video 1/1 (frame 207/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 133.1ms\n",
      "video 1/1 (frame 208/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 134.0ms\n",
      "video 1/1 (frame 209/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 144.8ms\n",
      "video 1/1 (frame 210/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 125.1ms\n",
      "video 1/1 (frame 211/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 121.4ms\n",
      "video 1/1 (frame 212/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 133.7ms\n",
      "video 1/1 (frame 213/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 138.1ms\n",
      "video 1/1 (frame 214/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 127.5ms\n",
      "video 1/1 (frame 215/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 138.8ms\n",
      "video 1/1 (frame 216/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 114.4ms\n",
      "video 1/1 (frame 217/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 128.3ms\n",
      "video 1/1 (frame 218/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 139.3ms\n",
      "video 1/1 (frame 219/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 134.7ms\n",
      "video 1/1 (frame 220/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 124.3ms\n",
      "video 1/1 (frame 221/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 144.6ms\n",
      "video 1/1 (frame 222/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 138.5ms\n",
      "video 1/1 (frame 223/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 147.4ms\n",
      "video 1/1 (frame 224/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 116.2ms\n",
      "video 1/1 (frame 225/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 145.3ms\n",
      "video 1/1 (frame 226/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 129.8ms\n",
      "video 1/1 (frame 227/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 113.3ms\n",
      "video 1/1 (frame 228/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 130.0ms\n",
      "video 1/1 (frame 229/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 117.8ms\n",
      "video 1/1 (frame 230/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 114.3ms\n",
      "video 1/1 (frame 231/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 132.3ms\n",
      "video 1/1 (frame 232/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 119.9ms\n",
      "video 1/1 (frame 233/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 124.1ms\n",
      "video 1/1 (frame 234/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 120.7ms\n",
      "video 1/1 (frame 235/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 132.6ms\n",
      "video 1/1 (frame 236/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 127.0ms\n",
      "video 1/1 (frame 237/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 138.0ms\n",
      "video 1/1 (frame 238/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 132.5ms\n",
      "video 1/1 (frame 239/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 124.8ms\n",
      "video 1/1 (frame 240/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 129.4ms\n",
      "video 1/1 (frame 241/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 132.3ms\n",
      "video 1/1 (frame 242/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 121.4ms\n",
      "video 1/1 (frame 243/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 122.2ms\n",
      "video 1/1 (frame 244/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 134.9ms\n",
      "video 1/1 (frame 245/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 132.4ms\n",
      "video 1/1 (frame 246/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 139.9ms\n",
      "video 1/1 (frame 247/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 110.5ms\n",
      "video 1/1 (frame 248/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 120.2ms\n",
      "video 1/1 (frame 249/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 136.4ms\n",
      "video 1/1 (frame 250/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 133.2ms\n",
      "video 1/1 (frame 251/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 116.0ms\n",
      "video 1/1 (frame 252/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 139.3ms\n",
      "video 1/1 (frame 253/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 113.1ms\n",
      "video 1/1 (frame 254/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 131.4ms\n",
      "video 1/1 (frame 255/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 142.6ms\n",
      "video 1/1 (frame 256/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 126.3ms\n",
      "video 1/1 (frame 257/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 140.8ms\n",
      "video 1/1 (frame 258/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 131.0ms\n",
      "video 1/1 (frame 259/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 132.8ms\n",
      "video 1/1 (frame 260/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 112.8ms\n",
      "video 1/1 (frame 261/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 109.4ms\n",
      "video 1/1 (frame 262/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 130.3ms\n",
      "video 1/1 (frame 263/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 134.5ms\n",
      "video 1/1 (frame 264/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 119.3ms\n",
      "video 1/1 (frame 265/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 130.8ms\n",
      "video 1/1 (frame 266/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 146.0ms\n",
      "video 1/1 (frame 267/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 130.5ms\n",
      "video 1/1 (frame 268/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 130.1ms\n",
      "video 1/1 (frame 269/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 126.0ms\n",
      "video 1/1 (frame 270/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 133.9ms\n",
      "video 1/1 (frame 271/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 144.0ms\n",
      "video 1/1 (frame 272/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 134.2ms\n",
      "video 1/1 (frame 273/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 152.9ms\n",
      "video 1/1 (frame 274/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 133.5ms\n",
      "video 1/1 (frame 275/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 116.7ms\n",
      "video 1/1 (frame 276/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 117.2ms\n",
      "video 1/1 (frame 277/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 145.8ms\n",
      "video 1/1 (frame 278/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 137.5ms\n",
      "video 1/1 (frame 279/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 182.5ms\n",
      "video 1/1 (frame 280/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 131.1ms\n",
      "video 1/1 (frame 281/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 124.7ms\n",
      "video 1/1 (frame 282/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 130.5ms\n",
      "video 1/1 (frame 283/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 134.5ms\n",
      "video 1/1 (frame 284/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 117.2ms\n",
      "video 1/1 (frame 285/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 131.5ms\n",
      "video 1/1 (frame 286/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 155.0ms\n",
      "video 1/1 (frame 287/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 133.8ms\n",
      "video 1/1 (frame 288/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 130.5ms\n",
      "video 1/1 (frame 289/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 144.6ms\n",
      "video 1/1 (frame 290/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 135.6ms\n",
      "video 1/1 (frame 291/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 150.6ms\n",
      "video 1/1 (frame 292/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 134.1ms\n",
      "video 1/1 (frame 293/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 137.2ms\n",
      "video 1/1 (frame 294/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 116.4ms\n",
      "video 1/1 (frame 295/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 133.9ms\n",
      "video 1/1 (frame 296/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 115.2ms\n",
      "video 1/1 (frame 297/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 116.8ms\n",
      "video 1/1 (frame 298/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 150.6ms\n",
      "video 1/1 (frame 299/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 137.6ms\n",
      "video 1/1 (frame 300/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 motorcycle, 134.5ms\n",
      "video 1/1 (frame 301/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 117.0ms\n",
      "video 1/1 (frame 302/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 132.3ms\n",
      "video 1/1 (frame 303/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 175.1ms\n",
      "video 1/1 (frame 304/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 motorcycle, 145.2ms\n",
      "video 1/1 (frame 305/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 motorcycle, 150.9ms\n",
      "video 1/1 (frame 306/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 120.2ms\n",
      "video 1/1 (frame 307/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 161.2ms\n",
      "video 1/1 (frame 308/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 183.0ms\n",
      "video 1/1 (frame 309/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 548.5ms\n",
      "video 1/1 (frame 310/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 325.9ms\n",
      "video 1/1 (frame 311/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 268.8ms\n",
      "video 1/1 (frame 312/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 279.6ms\n",
      "video 1/1 (frame 313/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 249.5ms\n",
      "video 1/1 (frame 314/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 217.1ms\n",
      "video 1/1 (frame 315/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bicycle, 142.2ms\n",
      "video 1/1 (frame 316/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 bicycle, 166.4ms\n",
      "video 1/1 (frame 317/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 180.5ms\n",
      "video 1/1 (frame 318/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bicycle, 176.8ms\n",
      "video 1/1 (frame 319/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 302.1ms\n",
      "video 1/1 (frame 320/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 241.7ms\n",
      "video 1/1 (frame 321/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 425.0ms\n",
      "video 1/1 (frame 322/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 390.0ms\n",
      "video 1/1 (frame 323/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 212.2ms\n",
      "video 1/1 (frame 324/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 236.1ms\n",
      "video 1/1 (frame 325/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 232.8ms\n",
      "video 1/1 (frame 326/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 272.1ms\n",
      "video 1/1 (frame 327/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 258.9ms\n",
      "video 1/1 (frame 328/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 408.2ms\n",
      "video 1/1 (frame 329/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 250.7ms\n",
      "video 1/1 (frame 330/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 296.5ms\n",
      "video 1/1 (frame 331/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 206.4ms\n",
      "video 1/1 (frame 332/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 267.8ms\n",
      "video 1/1 (frame 333/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 314.7ms\n",
      "video 1/1 (frame 334/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 232.0ms\n",
      "video 1/1 (frame 335/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 387.2ms\n",
      "video 1/1 (frame 336/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 239.6ms\n",
      "video 1/1 (frame 337/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 158.8ms\n",
      "video 1/1 (frame 338/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 199.6ms\n",
      "video 1/1 (frame 339/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 244.6ms\n",
      "video 1/1 (frame 340/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 198.6ms\n",
      "video 1/1 (frame 341/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 194.0ms\n",
      "video 1/1 (frame 342/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 177.6ms\n",
      "video 1/1 (frame 343/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bird, 221.4ms\n",
      "video 1/1 (frame 344/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bird, 220.0ms\n",
      "video 1/1 (frame 345/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bird, 187.5ms\n",
      "video 1/1 (frame 346/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bird, 261.3ms\n",
      "video 1/1 (frame 347/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bird, 238.6ms\n",
      "video 1/1 (frame 348/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bird, 228.7ms\n",
      "video 1/1 (frame 349/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 213.2ms\n",
      "video 1/1 (frame 350/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bird, 236.3ms\n",
      "video 1/1 (frame 351/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 1 bird, 194.7ms\n",
      "video 1/1 (frame 352/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 158.1ms\n",
      "video 1/1 (frame 353/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 199.7ms\n",
      "video 1/1 (frame 354/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 218.8ms\n",
      "video 1/1 (frame 355/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 215.4ms\n",
      "video 1/1 (frame 356/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 169.5ms\n",
      "video 1/1 (frame 357/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 204.9ms\n",
      "video 1/1 (frame 358/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 187.4ms\n",
      "video 1/1 (frame 359/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 188.0ms\n",
      "video 1/1 (frame 360/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 112.3ms\n",
      "video 1/1 (frame 361/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 133.8ms\n",
      "video 1/1 (frame 362/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 180.2ms\n",
      "video 1/1 (frame 363/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 128.3ms\n",
      "video 1/1 (frame 364/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 91.8ms\n",
      "video 1/1 (frame 365/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 146.9ms\n",
      "video 1/1 (frame 366/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 189.7ms\n",
      "video 1/1 (frame 367/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 91.2ms\n",
      "video 1/1 (frame 368/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 100.2ms\n",
      "video 1/1 (frame 369/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 115.3ms\n",
      "video 1/1 (frame 370/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 135.2ms\n",
      "video 1/1 (frame 371/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 95.1ms\n",
      "video 1/1 (frame 372/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 88.3ms\n",
      "video 1/1 (frame 373/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bird, 114.1ms\n",
      "video 1/1 (frame 374/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bird, 120.6ms\n",
      "video 1/1 (frame 375/375) c:\\Users\\54583374\\Desktop\\CLASE\\Visin por Computador\\Prcticas\\Vision-por-Computador\\Prctica 4\\Material P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 1 bird, 96.4ms\n",
      "Speed: 2.4ms preprocess, 146.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('YOLO/yolo11n.pt') #Contenedores\n",
    "#model = YOLO('yolov11n-seg.pt') #Máscaras\n",
    "#model = YOLO('yolo11n-pose.pt')  #Pose\n",
    "\n",
    "#Para un vídeo \n",
    "filename = \"Material P4/TGC23_PdH_C0056cut.mp4\"\n",
    "results = model.track(source=filename, show=True)  # BoT-SORT tracker (por defecto)\n",
    "#results = model.track(source=filename, show=True, tracker=\"bytetrack.yaml\")  # ByteTrack tracker\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de caracteres tras instalar pytesseract y tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eng', 'osd']\n",
      "Hasta el infinito y mas alla\n",
      "\n",
      "Texto: Hasta (96.00%)\n",
      "Contenedor: (57, 95, 176, 130)\n",
      "Texto: el (93.00%)\n",
      "Contenedor: (194, 95, 226, 130)\n",
      "Texto: infinito (91.00%)\n",
      "Contenedor: (246, 95, 380, 130)\n",
      "Texto: y (92.00%)\n",
      "Contenedor: (408, 104, 418, 140)\n",
      "Texto: mas (96.00%)\n",
      "Contenedor: (435, 94, 521, 130)\n",
      "Texto: alla (96.00%)\n",
      "Contenedor: (538, 94, 609, 130)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 37\u001b[0m\n\u001b[0;32m     33\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mrectangle(img, (x, y), (x \u001b[38;5;241m+\u001b[39m w, y \u001b[38;5;241m+\u001b[39m h), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     35\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTexto: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconf\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mContenedor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx,y,x\u001b[38;5;241m+\u001b[39mw,y\u001b[38;5;241m+\u001b[39mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "# Tesseract\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "# Previamente debes descargar los ejecutables\n",
    "# Si la ruta de Tesseract no está en el PATH, ruta al ejecutable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "# Lenguajes disponibles\n",
    "print(pytesseract.get_languages(config=''))\n",
    "\n",
    "#Cargo imagen y ocnvierto a RGB\n",
    "img = cv2.imread('Material P4/ocr_test.tif') \n",
    "\n",
    "if img is not None:\n",
    "    #Convierte a RGB antes de procesar\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Texto localizado\n",
    "    print(pytesseract.image_to_string(img))\n",
    "\n",
    "    #Texto y localización en imagen de cada palabra\n",
    "    d = pytesseract.image_to_data(img_rgb, output_type=Output.DICT)\n",
    "\n",
    "    n_boxes = len(d['text'])\n",
    "    for i in range(n_boxes):\n",
    "        #Nivel de confianza\n",
    "        if int(d['conf'][i]) > 60:\n",
    "            text = d['text'][i]\n",
    "            conf = d['conf'][i]\n",
    "            (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            print(f'Texto: {text} ({conf:.2f}%)\\nContenedor: {x,y,x+w,y+h}')\n",
    "\n",
    "    cv2.imshow('img', img_rgb)\n",
    "    cv2.waitKey(-1)\n",
    "\n",
    "   \n",
    "\n",
    "else:\n",
    "    print('Error de imagen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de caracteres tras instalar easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto: Hasta el infinito y más allá\n",
      "Probabilidad: 0.67\n",
      "Contenedor: ((49, 85), (617, 147))\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "\n",
    "#Carga del modelo de lengua\n",
    "reader = easyocr.Reader(['es']) \n",
    "\n",
    "#Reconocimiento de una imagen\n",
    "res = reader.readtext('Material P4/ocr_test.tif')\n",
    "\n",
    "for (bbox, text, prob) in res:\n",
    "    # Coordenadas en orden \n",
    "    (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "    print(f'\\nTexto: {text}\\nProbabilidad: {prob:.2f}\\nContenedor: {tuple(map(int, top_left)),tuple(map(int, bottom_right))}')\n",
    "\n",
    "\n",
    "#Con restricción de caracteres reconocibles\n",
    "#result = reader.readtext('toy.tif', allowlist ='0123456789')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
