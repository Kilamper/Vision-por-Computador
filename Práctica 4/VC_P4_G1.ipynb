{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Python>=3.10 is required, but Python==3.9.20 is currently installed \n"
     ]
    }
   ],
   "source": [
    "import cv2  \n",
    "import math \n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimiento. Requiere instalar lap con pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 1 bus, 105.7ms\n",
      "Speed: 8.0ms preprocess, 105.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> truck\n",
      "\n",
      "0: 352x416 1 License_Plate, 80.6ms\n",
      "Speed: 0.0ms preprocess, 80.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.85\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 97.3ms\n",
      "Speed: 0.0ms preprocess, 97.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 105.5ms\n",
      "Speed: 0.0ms preprocess, 105.5ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> truck\n",
      "\n",
      "0: 352x416 1 License_Plate, 65.0ms\n",
      "Speed: 6.5ms preprocess, 65.0ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.82\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 56.2ms\n",
      "Speed: 0.0ms preprocess, 56.2ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 73.0ms\n",
      "Speed: 8.0ms preprocess, 73.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> truck\n",
      "\n",
      "0: 352x416 1 License_Plate, 48.4ms\n",
      "Speed: 0.0ms preprocess, 48.4ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.82\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 48.4ms\n",
      "Speed: 0.0ms preprocess, 48.4ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 60.8ms\n",
      "Speed: 4.2ms preprocess, 60.8ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 41.0ms\n",
      "Speed: 0.0ms preprocess, 41.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.84\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 41.2ms\n",
      "Speed: 8.0ms preprocess, 41.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 65.5ms\n",
      "Speed: 8.2ms preprocess, 65.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 41.9ms\n",
      "Speed: 0.0ms preprocess, 41.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.82\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 48.4ms\n",
      "Speed: 8.2ms preprocess, 48.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 79.8ms\n",
      "Speed: 1.2ms preprocess, 79.8ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 56.8ms\n",
      "Speed: 0.0ms preprocess, 56.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.81\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 41.2ms\n",
      "Speed: 0.0ms preprocess, 41.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 64.8ms\n",
      "Speed: 8.6ms preprocess, 64.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 40.9ms\n",
      "Speed: 8.0ms preprocess, 40.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.8\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 48.8ms\n",
      "Speed: 0.0ms preprocess, 48.8ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 64.4ms\n",
      "Speed: 9.0ms preprocess, 64.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 41.0ms\n",
      "Speed: 8.1ms preprocess, 41.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.79\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 48.6ms\n",
      "Speed: 0.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 66.1ms\n",
      "Speed: 0.0ms preprocess, 66.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 41.0ms\n",
      "Speed: 0.0ms preprocess, 41.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.79\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 47.5ms\n",
      "Speed: 0.0ms preprocess, 47.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 74.0ms\n",
      "Speed: 0.0ms preprocess, 74.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.95\n",
      "Clase --> truck\n",
      "\n",
      "0: 288x416 1 License_Plate, 57.3ms\n",
      "Speed: 0.0ms preprocess, 57.3ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.81\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 40.2ms\n",
      "Speed: 0.0ms preprocess, 40.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 72.3ms\n",
      "Speed: 2.1ms preprocess, 72.3ms inference, 0.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> truck\n",
      "\n",
      "0: 288x416 1 License_Plate, 42.0ms\n",
      "Speed: 0.0ms preprocess, 42.0ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.81\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 48.5ms\n",
      "Speed: 0.0ms preprocess, 48.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 63.7ms\n",
      "Speed: 1.9ms preprocess, 63.7ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> truck\n",
      "\n",
      "0: 288x416 1 License_Plate, 40.7ms\n",
      "Speed: 0.0ms preprocess, 40.7ms inference, 8.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.79\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 40.5ms\n",
      "Speed: 7.5ms preprocess, 40.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 61.6ms\n",
      "Speed: 11.5ms preprocess, 61.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.94\n",
      "Clase --> truck\n",
      "\n",
      "0: 288x416 1 License_Plate, 40.1ms\n",
      "Speed: 0.1ms preprocess, 40.1ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.79\n",
      "Clase --> car\n",
      "\n",
      "0: 320x416 (no detections), 48.6ms\n",
      "Speed: 0.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 64.7ms\n",
      "Speed: 0.8ms preprocess, 64.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> truck\n",
      "\n",
      "0: 288x416 1 License_Plate, 40.5ms\n",
      "Speed: 7.5ms preprocess, 40.5ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.8\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 48.5ms\n",
      "Speed: 0.0ms preprocess, 48.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 66.2ms\n",
      "Speed: 0.0ms preprocess, 66.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> truck\n",
      "\n",
      "0: 288x416 1 License_Plate, 40.5ms\n",
      "Speed: 0.0ms preprocess, 40.5ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.78\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 48.5ms\n",
      "Speed: 0.0ms preprocess, 48.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 65.8ms\n",
      "Speed: 1.3ms preprocess, 65.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> truck\n",
      "\n",
      "0: 288x416 1 License_Plate, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.78\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 48.2ms\n",
      "Speed: 0.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 73.0ms\n",
      "Speed: 0.0ms preprocess, 73.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> truck\n",
      "\n",
      "0: 288x416 1 License_Plate, 48.3ms\n",
      "Speed: 0.0ms preprocess, 48.3ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.79\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 57.2ms\n",
      "Speed: 0.0ms preprocess, 57.2ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 98.9ms\n",
      "Speed: 0.0ms preprocess, 98.9ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> truck\n",
      "\n",
      "0: 288x416 1 License_Plate, 48.5ms\n",
      "Speed: 0.0ms preprocess, 48.5ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.78\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 48.6ms\n",
      "Speed: 7.9ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 63.8ms\n",
      "Speed: 2.9ms preprocess, 63.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 32.0ms\n",
      "Speed: 0.0ms preprocess, 32.0ms inference, 8.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.77\n",
      "Clase --> car\n",
      "\n",
      "0: 352x416 (no detections), 48.5ms\n",
      "Speed: 0.0ms preprocess, 48.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 63.2ms\n",
      "Speed: 1.8ms preprocess, 63.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 46.7ms\n",
      "Speed: 0.0ms preprocess, 46.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.79\n",
      "Clase --> car\n",
      "\n",
      "0: 384x416 (no detections), 72.2ms\n",
      "Speed: 0.0ms preprocess, 72.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 72.2ms\n",
      "Speed: 9.0ms preprocess, 72.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 48.0ms\n",
      "Speed: 0.0ms preprocess, 48.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.76\n",
      "Clase --> car\n",
      "\n",
      "0: 384x416 (no detections), 56.3ms\n",
      "Speed: 0.0ms preprocess, 56.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 70.9ms\n",
      "Speed: 2.4ms preprocess, 70.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 40.3ms\n",
      "Speed: 8.6ms preprocess, 40.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.74\n",
      "Clase --> car\n",
      "\n",
      "0: 384x416 (no detections), 48.5ms\n",
      "Speed: 8.0ms preprocess, 48.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 73.4ms\n",
      "Speed: 0.0ms preprocess, 73.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 48.9ms\n",
      "Speed: 0.0ms preprocess, 48.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.75\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 81.5ms\n",
      "Speed: 8.0ms preprocess, 81.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 72.6ms\n",
      "Speed: 5.9ms preprocess, 72.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> truck\n",
      "\n",
      "0: 288x416 1 License_Plate, 39.8ms\n",
      "Speed: 0.0ms preprocess, 39.8ms inference, 8.7ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Confianza ---> 0.72\n",
      "Clase --> car\n",
      "\n",
      "0: 384x416 (no detections), 49.0ms\n",
      "Speed: 8.0ms preprocess, 49.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 62.1ms\n",
      "Speed: 3.1ms preprocess, 62.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.89\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 2 License_Plates, 41.0ms\n",
      "Speed: 0.0ms preprocess, 41.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.71\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 57.0ms\n",
      "Speed: 0.0ms preprocess, 57.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 71.9ms\n",
      "Speed: 1.3ms preprocess, 71.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 40.5ms\n",
      "Speed: 4.2ms preprocess, 40.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.71\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 56.5ms\n",
      "Speed: 0.0ms preprocess, 56.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 61.6ms\n",
      "Speed: 11.5ms preprocess, 61.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 128.8ms\n",
      "Speed: 0.0ms preprocess, 128.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.69\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 56.9ms\n",
      "Speed: 0.0ms preprocess, 56.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 79.3ms\n",
      "Speed: 1.2ms preprocess, 79.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 56.7ms\n",
      "Speed: 0.0ms preprocess, 56.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.68\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 65.3ms\n",
      "Speed: 8.0ms preprocess, 65.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 97.4ms\n",
      "Speed: 10.0ms preprocess, 97.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 40.4ms\n",
      "Speed: 7.5ms preprocess, 40.4ms inference, 8.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.65\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 57.0ms\n",
      "Speed: 0.0ms preprocess, 57.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 73.1ms\n",
      "Speed: 4.1ms preprocess, 73.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> truck\n",
      "\n",
      "0: 352x416 2 License_Plates, 48.0ms\n",
      "Speed: 0.0ms preprocess, 48.0ms inference, 8.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 56.6ms\n",
      "Speed: 0.0ms preprocess, 56.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 72.9ms\n",
      "Speed: 2.2ms preprocess, 72.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.91\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 48.9ms\n",
      "Speed: 0.0ms preprocess, 48.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 48.9ms\n",
      "Speed: 0.0ms preprocess, 48.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 69.8ms\n",
      "Speed: 3.8ms preprocess, 69.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.9\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 49.1ms\n",
      "Speed: 0.0ms preprocess, 49.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.64\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 58.1ms\n",
      "Speed: 0.0ms preprocess, 58.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 65.7ms\n",
      "Speed: 8.0ms preprocess, 65.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> truck\n",
      "\n",
      "0: 320x416 1 License_Plate, 49.0ms\n",
      "Speed: 0.0ms preprocess, 49.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Confianza ---> 0.65\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 64.0ms\n",
      "Speed: 0.0ms preprocess, 64.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 73.5ms\n",
      "Speed: 0.0ms preprocess, 73.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> truck\n",
      "\n",
      "0: 352x416 1 License_Plate, 47.9ms\n",
      "Speed: 0.0ms preprocess, 47.9ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.63\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 65.6ms\n",
      "Speed: 0.0ms preprocess, 65.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 80.7ms\n",
      "Speed: 8.0ms preprocess, 80.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> truck\n",
      "\n",
      "0: 352x416 1 License_Plate, 57.5ms\n",
      "Speed: 0.0ms preprocess, 57.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.62\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 56.5ms\n",
      "Speed: 7.5ms preprocess, 56.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 71.9ms\n",
      "Speed: 0.0ms preprocess, 71.9ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.92\n",
      "Clase --> truck\n",
      "\n",
      "0: 352x416 1 License_Plate, 56.3ms\n",
      "Speed: 6.0ms preprocess, 56.3ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.6\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 56.8ms\n",
      "Speed: 0.0ms preprocess, 56.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 384x640 1 car, 1 bus, 70.5ms\n",
      "Speed: 1.1ms preprocess, 70.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Confianza ---> 0.93\n",
      "Clase --> truck\n",
      "\n",
      "0: 352x416 1 License_Plate, 40.7ms\n",
      "Speed: 2.5ms preprocess, 40.7ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Confianza ---> 0.61\n",
      "Clase --> car\n",
      "\n",
      "0: 416x416 (no detections), 56.8ms\n",
      "Speed: 0.0ms preprocess, 56.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# si hay imagen válida\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:  \n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Seguimiento, con persistencia entre fotogramas\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Para cada detección\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\ultralytics\\engine\\model.py:601\u001b[0m, in \u001b[0;36mModel.track\u001b[1;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# batch-size 1 for tracking in videos\u001b[39;00m\n\u001b[0;32m    600\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source\u001b[38;5;241m=\u001b[39msource, stream\u001b[38;5;241m=\u001b[39mstream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\ultralytics\\engine\\model.py:554\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\ultralytics\\engine\\predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\ultralytics\\engine\\predictor.py:254\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 254\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\ultralytics\\engine\\predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    138\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    141\u001b[0m )\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:465\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 465\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\ultralytics\\nn\\tasks.py:112\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\ultralytics\\nn\\tasks.py:130\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\ultralytics\\nn\\tasks.py:151\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    152\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:237\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    238\u001b[0m     y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\torch\\nn\\modules\\activation.py:405\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\torch\\nn\\functional.py:2104\u001b[0m, in \u001b[0;36msilu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   2102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[0;32m   2103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m-> 2104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import easyocr\n",
    "# Variable booleana que indica si quieres guardar en memoria (False) o visualizar en pantalla (True)\n",
    "display = False\n",
    "#Carga del modelo de lengua\n",
    "reader = easyocr.Reader(['es']) \n",
    "\n",
    "# Carga del modelo, descarga en disco si no está presente en la carpeta\n",
    "model = YOLO('YOLO/yolo11n.pt') #Contenedores\n",
    "license_plate_model = YOLO('YOLO/best.pt')\n",
    "\n",
    "# Etiqueta de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\", \"truck\"]\n",
    "\n",
    "\n",
    "# Captura desde la webcam\n",
    "vid = cv2.VideoCapture(\"YOLO/C0142.MP4\")\n",
    "if not display:\n",
    "    frame_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    output_video = cv2.VideoWriter('YOLO/resultados.avi', cv2.VideoWriter_fourcc(*'XVID'), 20, (frame_width, frame_height))\n",
    "track_history = defaultdict(lambda: [])\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen válida\n",
    "    if ret:  \n",
    "        # Seguimiento, con persistencia entre fotogramas\n",
    "        results = model.track(img, persist=True, classes = [0,1,2,3,5,7])\n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "                #Etiqueta de seguimiento\n",
    "                if box.id is not None:\n",
    "                    track_id = str(int(box.id[0].tolist()))\n",
    "                else:\n",
    "                    track_id = ''\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confianza --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Clase -->\", classNames[cls])\n",
    "\n",
    "                if cls >= 2:\n",
    "                    # Recorta el contenedor del coche\n",
    "                    car_crop = img[y1:y2, x1:x2]\n",
    "\n",
    "                    # Detecta la matrícula en el contenedor del coche\n",
    "                    license_plate_results = license_plate_model.predict(car_crop)\n",
    "                    possible_licenses = {\"Not Found\": 0}\n",
    "                    # Procesa cada detección en el contenedor del coche\n",
    "                    for lp_result in license_plate_results:\n",
    "                        lp_boxes = lp_result.boxes\n",
    "                        for lp_box in lp_boxes:\n",
    "                            lp_x1, lp_y1, lp_x2, lp_y2 = lp_box.xyxy[0]\n",
    "                            lp_x1, lp_y1, lp_x2, lp_y2 = int(lp_x1), int(lp_y1), int(lp_x2), int(lp_y2)\n",
    "                            #Reconocimiento del texto\n",
    "                            res = reader.readtext(img[lp_y1:lp_y2, lp_x1:lp_x2])\n",
    "                            for (bbox, text, prob) in res:\n",
    "                                if possible_licenses[text] is not None and possible_licenses[text] < prob:\n",
    "                                    possible_licenses[text] = prob\n",
    "                            # Ajustar coordenadas al área de imagen completa\n",
    "                            lp_x1 += x1\n",
    "                            lp_x2 += x1\n",
    "                            lp_y1 += y1\n",
    "                            lp_y2 += y1\n",
    "\n",
    "                            # Dibuja el contenedor de la matrícula sobre el coche\n",
    "                            cv2.rectangle(img, (lp_x1, lp_y1), (lp_x2, lp_y2), (0, 255, 0), 2)\n",
    "                            cv2.putText(img,\n",
    "                                        f\"Matricula: {max(possible_licenses, key=possible_licenses.get)}\",\n",
    "                                        (lp_x1, lp_y1 - 10),\n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                # Convierte identificador numérico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, track_id + ' ' + classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        if display:\n",
    "            cv2.imshow('Vid', img)\n",
    "        else:\n",
    "            # Muestra fotograma\n",
    "            output_video.write(img)\n",
    "        # Detenemos pulsado ESC\n",
    "        if cv2.waitKey(20) == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "if display:\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    output_video.release()  # Libera el archivo de video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
